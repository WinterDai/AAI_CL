# -*- coding: utf-8 -*-
"""
NetlistSpefVersionChecker.py - Checker Implementation for IMP-10-0-0-00

Description:
    Confirm the netlist/spef version is correct.

Author: CodeGen Agent
Created: 2026-01-03
Version: v1.0.0

This file was auto-generated by CodeGen Agent.
Manual modifications may be overwritten on regeneration.
"""


from pathlib import Path
import gzip
import re
import sys
from typing import List, Dict, Tuple, Optional, Any


# Add common module to path
_SCRIPT_DIR = Path(__file__).resolve().parent
_CHECK_MODULES_DIR = _SCRIPT_DIR.parents[2]  # Go up to Check_modules/
_COMMON_DIR = _CHECK_MODULES_DIR / 'common'
if str(_COMMON_DIR) not in sys.path:
    sys.path.insert(0, str(_COMMON_DIR))

# Framework imports
from base_checker import BaseChecker, CheckResult, ConfigurationError
from output_formatter import DetailItem, Severity, create_check_result
from checker_templates.waiver_handler_template import WaiverHandlerMixin
from checker_templates.output_builder_template import OutputBuilderMixin

from checker_templates.input_file_parser_template import InputFileParserMixin


# MANDATORY: Inherit mixins in correct order (InputFileParserMixin first if used)
class NetlistSpefVersionChecker(InputFileParserMixin, OutputBuilderMixin, WaiverHandlerMixin, BaseChecker):
    """
    IMP-10-0-0-00: Confirm the netlist/spef version is correct.
    
    Checking Types:
    - Type 1: requirements=N/A, pattern_items [], waivers=N/A/0 → Boolean Check
    - Type 2: requirements>0, pattern_items [...], waivers=N/A/0 → Value Check
    - Type 3: requirements>0, pattern_items [...], waivers>0 → Value Check with Waiver Logic
    - Type 4: requirements=N/A, pattern_items [], waivers>0 → Boolean Check with Waiver Logic
    
    Template Library v1.1.0:
    - Uses InputFileParserMixin for parsing (parse_log_with_patterns, normalize_command)
    - Uses WaiverHandlerMixin for waiver processing (parse_waive_items, match_waiver_entry)
    - Uses OutputBuilderMixin for result construction (build_complete_output)
    """
    
    # =========================================================================
    # UNIFIED DESCRIPTIONS - Class-level constants (LLM-Generated)
    # =========================================================================
    # Found/Missing descriptions
    FOUND_DESC = "netlist/SPEF version metadata found"
    MISSING_DESC = "netlist/SPEF version metadata not found or pattern not satisfied"
    WAIVED_DESC = "version check waived for current flow stage"
    EXTRA_DESC = "Additional information or warnings"

    # Detailed reasons
    FOUND_REASON = "Version metadata extracted from {file_type}: {version_string}"
    MISSING_REASON = "Version metadata missing in {file_type} or pattern '{pattern}' not matched"
    WAIVED_BASE_REASON = "Version check waived: {waiver_name}"
    EXTRA_REASON = "Flow stage: {flow_step}, SPEF reading status: {spef_status}"
    UNUSED_WAIVER_REASON = "Waiver '{waiver_name}' defined but not applied (version metadata found)"
    
    def __init__(self):
        """Initialize the checker."""
        super().__init__(
            check_module="10.0_STA_DCD_CHECK",
            item_id="IMP-10-0-0-00",
            item_desc="Confirm the netlist/spef version is correct."
        )
        # MANDATORY: Metadata tracking for debug (Golden pattern)
        # Used by helper methods to track line numbers for DetailItem
        self._metadata: Dict[str, Dict[str, Any]] = {}
        # Store parsed data
        self._parsed_items: List[Dict] = []
    
    # =========================================================================
    # Main Check Execution (Template - Fixed, v2.1 Golden-Aligned)
    # =========================================================================
    
    def execute_check(self) -> CheckResult:
        """
        Execute check with automatic type detection and delegation.
        
        v2.1: Aligned with Golden design pattern:
        1. Parse input files first via _parse_input_files()
        2. Pass parsed data to _execute_typeN(parsed_data)
        
        Returns:
            CheckResult based on detected checker type
        """
        try:
            if self.root is None:
                raise RuntimeError("Checker not initialized. Call init_checker() first.")
            
            # Parse input files first (Golden pattern)
            parsed_data = self._parse_input_files()
            
            # Detect checker type (use BaseChecker method)
            checker_type = self.detect_checker_type()
            
            # Execute based on type, passing parsed data
            if checker_type == 1:
                return self._execute_type1(parsed_data)
            elif checker_type == 2:
                return self._execute_type2(parsed_data)
            elif checker_type == 3:
                return self._execute_type3(parsed_data)
            else:  # checker_type == 4
                return self._execute_type4(parsed_data)
        except ConfigurationError as e:
            return e.check_result
    
    # =========================================================================
    # Input Parsing (LLM-Generated)
    # =========================================================================
    
    def _parse_input_files(self) -> Dict[str, Any]:
        """
        Parse input files to extract netlist/SPEF version metadata.
        
        Returns:
            Dict[str, Any] with structure:
            {
                'netlist_info': {
                    'status': 'Success'/'Not Found',
                    'path': str (if file exists),
                    'relative_path': str (if file doesn't exist but path found),
                    'version': str,
                    'date': str,
                    'top_module': str
                },
                'spef_info': {
                    'status': 'Success'/'Skipped'/'Not Found',
                    'path': str,
                    'version': str,
                    'date': str,
                    'program': str,
                    'vendor': str,
                    'skip_reason': str (if skipped)
                },
                'flow_step': str,
                'errors': List[str]
            }
        """
        # Initialize metadata tracking
        self._metadata = {}
        
        # Validate input files
        valid_files, missing_files = self.validate_input_files()
        if not valid_files:
            raise ConfigurationError("No valid input files found")
        
        # Initialize result
        result = {
            'netlist_info': {'status': 'Not Found'},
            'spef_info': {'status': 'Not Found'},
            'flow_step': 'Unknown',
            'errors': []
        }
        
        # Parse STA log (primary source)
        sta_log = None
        for file_path in valid_files:
            if 'sta' in file_path.name.lower() and file_path.suffix == '.log':
                sta_log = file_path
                break
        
        if sta_log:
            try:
                sta_data = self._parse_sta_log(sta_log)
                result.update(sta_data)
            except Exception as e:
                result['errors'].append(f"Error parsing STA log: {str(e)}")
        
        # Parse netlist file if path found
        netlist_info = result.get('netlist_info', {})
        if netlist_info.get('path'):
            try:
                netlist_data = self._parse_netlist_file(Path(netlist_info['path']))
                result['netlist_info'].update(netlist_data)
            except Exception as e:
                result['errors'].append(f"Error parsing netlist file: {str(e)}")
        
        # Parse SPEF file if path found and not skipped
        spef_info = result.get('spef_info', {})
        if spef_info.get('status') != 'Skipped' and spef_info.get('path'):
            try:
                spef_data = self._parse_spef_file(Path(spef_info['path']))
                result['spef_info'].update(spef_data)
            except Exception as e:
                result['errors'].append(f"Error parsing SPEF file: {str(e)}")
        
        return result
    
    # =========================================================================
    # Type 1: Boolean Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 1: Boolean check - 存在即 PASS"""
        def parse_data():
            """调用共享的Boolean Check Logic"""
            return self._boolean_check_logic(parsed_data)
        
        return self.execute_boolean_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 2: Value Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 2: Value check - 匹配 pattern_items"""
        def parse_data():
            """调用共享的Pattern Check Logic"""
            return self._pattern_check_logic(parsed_data)
        
        return self.execute_value_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc="Pattern matched in version metadata",
            missing_desc="Pattern not found in version metadata",
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 3: Value Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 3: Value check with waiver - 复用 Type2 逻辑"""
        # Prepare info_items for display
        info_items = {}
        flow_step = parsed_data.get('flow_step', 'Unknown')
        if flow_step != 'Unknown':
            info_items['Flow Step'] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Current flow step: {flow_step}"
            }
        
        def parse_data():
            """调用共享的Pattern Check Logic (与Type2相同)"""
            return self._pattern_check_logic(parsed_data)
        
        return self.execute_value_check(
            parse_data_func=parse_data,
            has_waiver=True,
            info_items=info_items,
            found_desc="Pattern matched in version metadata",
            missing_desc="Pattern not found in version metadata",
            extra_desc=self.EXTRA_DESC,
            extra_severity=Severity.FAIL,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 4: Boolean Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 4: Boolean check with waiver - 复用 Type1 逻辑"""
        def parse_data():
            """调用共享的Boolean Check Logic (与Type1相同)"""
            return self._boolean_check_logic(parsed_data)
        
        return self.execute_boolean_check(
            parse_data_func=parse_data,
            has_waiver=True,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )

    # =========================================================================
    # Helper Methods (LLM-Generated)
    # =========================================================================
    
    def _build_name_extractor(self):
        """返回 name_extractor 函数，用于格式化输出"""
        def extract_name(name: str, metadata: Any) -> str:
            if isinstance(metadata, dict):
                version = metadata.get('version', '')
                date = metadata.get('date', '')
                path = metadata.get('path', '')
                
                # Format: "Name: path, Version: X, Date: Y"
                parts = [name]
                if path:
                    parts.append(f"Path: {Path(path).name}")
                if version:
                    parts.append(f"Version: {version}")
                if date:
                    parts.append(f"Date: {date}")
                
                return ", ".join(parts)
            return name
        return extract_name

    def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Boolean Check Logic (Type1/4 共享)
        
        核心业务逻辑：检查 netlist/SPEF 版本元数据是否存在
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Check netlist version metadata
        netlist_status = netlist_info.get('status', 'Not Found')
        if netlist_status == 'Success':
            if netlist_info.get('path'):
                # File exists and accessible
                metadata = self._metadata.get('netlist_success', {})
                found_items["Netlist Version"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': netlist_info.get('version', 'Unknown'),
                    'date': netlist_info.get('date', 'Unknown'),
                    'path': netlist_info.get('path', 'Unknown')
                }
            elif netlist_info.get('relative_path'):
                # ⚠️ CRITICAL: Path found but file not accessible → still count as found!
                metadata = self._metadata.get('netlist_success', {})
                found_items["Netlist Version"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'note': 'found in log, file not accessible',
                    'path': netlist_info['relative_path']
                }
        else:
            missing_items["Netlist Version"] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Status: {netlist_status}"
            }
        
        # Check SPEF version metadata
        spef_status = spef_info.get('status', 'Not Found')
        if spef_status == 'Success':
            if spef_info.get('path'):
                metadata = self._metadata.get('spef_success', {})
                found_items["SPEF Version"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': spef_info.get('version', 'Unknown'),
                    'date': spef_info.get('date', 'Unknown'),
                    'program': spef_info.get('program', 'Unknown'),
                    'path': spef_info.get('path', 'Unknown')
                }
        elif spef_status == 'Skipped':
            # ⚠️ CRITICAL: SPEF skipped → missing_items (not extra_items!)
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            missing_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        else:
            missing_items["SPEF Version"] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Status: {spef_status}"
            }
        
        # ⚠️ CRITICAL: Errors as extra_items (don't affect is_pass)
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                extra_items[f"Error: {error}"] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': 'Unexpected error during parsing'
                }
        
        return found_items, missing_items, extra_items


    def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Pattern Check Logic (Type2/3 共享)
        
        核心业务逻辑：在版本元数据中搜索 pattern_items
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        # Get pattern_items
        requirements = self.item_data.get('requirements', {})
        pattern_items = requirements.get('pattern_items', [])
        
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Build searchable content from version metadata
        searchable_content = []
        
        # Netlist metadata
        if netlist_info.get('version'):
            searchable_content.append({
                'text': f"Netlist Version: {netlist_info['version']}",
                'source': 'netlist',
                'metadata': netlist_info
            })
        if netlist_info.get('date'):
            searchable_content.append({
                'text': f"Netlist Date: {netlist_info['date']}",
                'source': 'netlist',
                'metadata': netlist_info
            })
        
        # SPEF metadata
        if spef_info.get('version'):
            searchable_content.append({
                'text': f"SPEF Version: {spef_info['version']}",
                'source': 'spef',
                'metadata': spef_info
            })
        if spef_info.get('date'):
            searchable_content.append({
                'text': f"SPEF Date: {spef_info['date']}",
                'source': 'spef',
                'metadata': spef_info
            })
        if spef_info.get('program'):
            searchable_content.append({
                'text': f"SPEF Program: {spef_info['program']}",
                'source': 'spef',
                'metadata': spef_info
            })
        
        # Match patterns
        for pattern in pattern_items:
            matched = False
            for content in searchable_content:
                if self._match_pattern_wildcard(content['text'], pattern):
                    source = content['source']
                    metadata = content['metadata']
                    meta_tracking = self._metadata.get(f'{source}_success', {})
                    
                    found_items[pattern] = {
                        'line_number': meta_tracking.get('line_number', 0),
                        'file_path': meta_tracking.get('file_path', ''),
                        'matched': content['text'],
                        'source': source,
                        'version': metadata.get('version', ''),
                        'date': metadata.get('date', '')
                    }
                    matched = True
                    break
            
            if not matched:
                missing_items[pattern] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': f"Pattern '{pattern}' not found in version metadata"
                }
        
        # Check SPEF skip status - add as extra_item if skipped (Type2/3 specific)
        if spef_info.get('status') == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            extra_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        
        return found_items, missing_items, extra_items


    def _parse_sta_log(self, sta_log: Path) -> Dict[str, Any]:
        """
        Parse STA log to extract netlist/SPEF file paths and metadata.
        
        Returns:
            Dict with netlist_info, spef_info, flow_step
        """
        result = {
            'netlist_info': {'status': 'Not Found'},
            'spef_info': {'status': 'Not Found'},
            'flow_step': 'Unknown'
        }
        
        try:
            with open(sta_log, 'r', errors='ignore') as f:
                for line_num, line in enumerate(f, 1):
                    # Extract netlist path
                    if 'read_netlist' in line:
                        match = re.search(r'read_netlist\s+(\S+)', line)
                        if match:
                            netlist_path_str = match.group(1)
                            netlist_path = Path(netlist_path_str)
                            if netlist_path.exists():
                                result['netlist_info']['path'] = str(netlist_path.resolve())
                            else:
                                # ⚠️ CRITICAL: Path found but file doesn't exist → save as relative_path
                                # Don't set status here! Wait for success indicator.
                                result['netlist_info']['relative_path'] = netlist_path_str
                    
                    # Netlist reading confirmation
                    elif 'Reading verilog netlist' in line:
                        match = re.search(r"Reading verilog netlist '([^']+)'", line)
                        if match and 'path' not in result['netlist_info']:
                            netlist_path = Path(match.group(1))
                            if netlist_path.exists():
                                result['netlist_info']['path'] = str(netlist_path.resolve())
                    
                    # Netlist success indicator
                    elif '*** Netlist is unique' in line or 'Netlist is unique' in line:
                        result['netlist_info']['status'] = 'Success'
                        self._metadata['netlist_success'] = {
                            'line_number': line_num,
                            'file_path': str(sta_log)
                        }
                    
                    # Top level cell
                    elif 'Top level cell is' in line:
                        match = re.search(r'Top level cell is (\w+)\.', line)
                        if match:
                            result['netlist_info']['top_module'] = match.group(1)
                    
                    # Flow step
                    elif '#@ flow_step:' in line:
                        match = re.search(r'#@ flow_step:(\w+)', line)
                        if match:
                            result['flow_step'] = match.group(1)
                    
                    # SPEF file path
                    elif 'read_spef' in line:
                        match = re.search(r'read_spef\s+(\S+)', line)
                        if match:
                            spef_path = Path(match.group(1))
                            if spef_path.exists():
                                result['spef_info']['path'] = str(spef_path.resolve())
                                result['spef_info']['status'] = 'Success'
                                self._metadata['spef_success'] = {
                                    'line_number': line_num,
                                    'file_path': str(sta_log)
                                }
                    
                    # SPEF skipped
                    elif '[INFO]' in line and 'Skipping SPEF reading' in line:
                        match = re.search(r'\[INFO\]\s*Skipping SPEF reading(.+)', line)
                        skip_reason = match.group(1).strip() if match else 'SPEF reading was skipped'
                        result['spef_info']['status'] = 'Skipped'
                        result['spef_info']['skip_reason'] = skip_reason
                        self._metadata['spef_skipped'] = {
                            'line_number': line_num,
                            'file_path': str(sta_log)
                        }
        
        except Exception as e:
            raise Exception(f"Failed to parse STA log: {str(e)}")
        
        return result


    def _parse_netlist_file(self, netlist_path: Path) -> Dict[str, Any]:
        """
        Parse netlist file header to extract version metadata.
        
        Returns:
            Dict with version, date, tool info
        """
        result = {}
        
        try:
            with open(netlist_path, 'r', errors='ignore') as f:
                # Only read first 100 lines (header)
                for line_num, line in enumerate(f, 1):
                    if line_num > 100:
                        break
                    
                    # Tool version
                    if '// Generated by' in line or '//Generated by' in line:
                        match = re.search(r'//\s*Generated by[:\s]+([^\n]+)', line)
                        if match:
                            result['version'] = match.group(1).strip()
                    
                    # Generation date
                    elif '// Date' in line or '//Date' in line:
                        match = re.search(r'//\s*Date[:\s]+([^\n]+)', line)
                        if match:
                            result['date'] = match.group(1).strip()
                    
                    # Version comment
                    elif '// Version' in line or '//Version' in line:
                        match = re.search(r'//\s*Version[:\s]+([^\n]+)', line)
                        if match and 'version' not in result:
                            result['version'] = match.group(1).strip()
                    
                    # Module name
                    elif line.strip().startswith('module '):
                        match = re.search(r'module\s+(\w+)\s*[#(;]', line)
                        if match:
                            result['top_module'] = match.group(1)
                            break  # Stop after finding module
        
        except Exception as e:
            raise Exception(f"Failed to parse netlist file: {str(e)}")
        
        return result


    def _parse_spef_file(self, spef_path: Path) -> Dict[str, Any]:
        """
        Parse SPEF file header to extract version metadata (IEEE 1481 standard).
        
        Returns:
            Dict with version, date, program, vendor, etc.
        """
        result = {}
        
        try:
            with open(spef_path, 'r', errors='ignore') as f:
                # Only read first 100 lines (header)
                for line_num, line in enumerate(f, 1):
                    if line_num > 100:
                        break
                    
                    # *VERSION
                    if line.startswith('*VERSION'):
                        match = re.search(r'\*VERSION\s+"([^"]+)"', line)
                        if match:
                            result['version'] = match.group(1)
                    
                    # *DATE
                    elif line.startswith('*DATE'):
                        match = re.search(r'\*DATE\s+"([^"]+)"', line)
                        if match:
                            result['date'] = match.group(1)
                    
                    # *PROGRAM
                    elif line.startswith('*PROGRAM'):
                        match = re.search(r'\*PROGRAM\s+"([^"]+)"', line)
                        if match:
                            result['program'] = match.group(1)
                    
                    # *VENDOR
                    elif line.startswith('*VENDOR'):
                        match = re.search(r'\*VENDOR\s+"([^"]+)"', line)
                        if match:
                            result['vendor'] = match.group(1)
                    
                    # *DESIGN
                    elif line.startswith('*DESIGN'):
                        match = re.search(r'\*DESIGN\s+"([^"]+)"', line)
                        if match:
                            result['design'] = match.group(1)
                    
                    # *SPEF (format version)
                    elif line.startswith('*SPEF'):
                        match = re.search(r'\*SPEF\s+"([^"]+)"', line)
                        if match:
                            result['spef_standard'] = match.group(1)
        
        except Exception as e:
            raise Exception(f"Failed to parse SPEF file: {str(e)}")
        
        return result


    def _match_pattern_wildcard(self, text: str, pattern: str) -> bool:
        """
        Match pattern with wildcard support (* matches any characters).
        
        Args:
            text: Text to search in
            pattern: Pattern with optional wildcards (e.g., "Generated on:*2025*")
        
        Returns:
            bool: True if pattern matches
        """
        # Convert wildcard pattern to regex
        # Escape special regex chars except *
        regex_pattern = re.escape(pattern).replace(r'\*', '.*')
        regex_pattern = f'^{regex_pattern}$'
        
        try:
            return bool(re.search(regex_pattern, text, re.IGNORECASE))
        except Exception:
            # Fallback to simple substring match
            return pattern.replace('*', '').lower() in text.lower()


# ============================================================================
# Entry Point (Template - Fixed, Golden-Aligned)
# ============================================================================

def init_checker() -> NetlistSpefVersionChecker:
    """Initialize and return the checker instance."""
    checker = NetlistSpefVersionChecker()
    checker.init_checker()
    return checker


if __name__ == '__main__':
    checker = init_checker()
    checker.execute_check()
    checker.write_output()
