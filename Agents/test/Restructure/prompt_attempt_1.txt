# ğŸ“š å­¦ä¹ ææ–™ (Grounding Data)

## ğŸ“‹ Data Structure Rules

âš ï¸ **CRITICAL**: All items MUST be `Dict[str, Dict]`, NOT List!

```python
# âœ… Correct
found_items["Item"] = {"line_number": 10, "file_path": "..."}

# âŒ Wrong
missing_items.append("Item")  # NO! Must be Dict
```

## ğŸ“‹ çœŸå® Log æ ·æœ¬ (æ­£åˆ™è¡¨è¾¾å¼è®¾è®¡ä¾æ®)

è¯·åŸºäºä»¥ä¸‹çœŸå®æ—¥å¿—è®¾è®¡æ­£åˆ™è¡¨è¾¾å¼ï¼š

### sta_post_syn.log
```
Read 20 cells in library 'tcbn03e_bwp143mh286l3p48cpd_mb_svtffgnp_0p825v_m40c_cbest_CCbest_T_ccs' 
Reading libset_ffgnp_0p825v_m40c_cbest_CCbest_T_cbest_CCbest_hold_ideal timing library '/process/tsmcN3/data/stdcell/n3ge/TSMC/tcbn03e_bwp143mh286l3p48cpd_mb_svt_110b/lvf/ccs/tcbn03e_bwp143mh286l3p48cpd_mb_svtffgnp_0p825v_m40c_cbest_CCbest_T_hm_lvf.lib.gz' ...
Read 20 cells in library 'tcbn03e_bwp143mh286l3p48cpd_mb_ulvtffgnp_0p825v_m40c_cbest_CCbest_T_ccs' 
reading netlists
<CMD> read_netlist C:\Users\yuyin\Desktop\CHECKLIST\IP_project_folder\dbs\phy_cmn_phase_align_digtop.v.gz
   - /process/tsmcN3/data/stdcell/n3ge/TSMC/tcbn03e_bwp143mh286l3p48cpd_mb_lvt_110b/spm/socv/tcbn03e_bwp143mh286l3p48cpd_mb_lvtffgnp_0p825v_125c_cbest_CCbest_T_sp.socv
   - /process/tsmcN3/data/stdcell/n3ge/TSMC/tcbn03e_bwp143mh286l3p48cpd_mb_svt_110b/spm/socv/tcbn03e_bwp143mh286l3p48cpd_mb_svtffgnp_0p825v_125c_cbest_CCbest_T_sp.socv

*** Memory Usage v#1 (Current mem = 2923.969M, initial mem = 828.688M) ***
... (truncated)
```


<semantic_intent>
  <check_target>Verify that the netlist/SPEF version metadata matches expected format or value</check_target>
  <data_flow>STA_Log references SPEF/Netlist files â†’ Extract file paths â†’ Parse SPEF *VERSION or Netlist header â†’ Verify version format/value</data_flow>
  <data_sources>
    <source name="STA_Log" data_role="indirect_reference">
      <role>Contains references to SPEF/netlist files and may contain version information</role>
    </source>
    <source name="SPEF" data_role="direct_source">
      <role>Primary parasitic extraction file containing version metadata</role>
    </source>
    <source name="Netlist_Verilog" data_role="direct_source">
      <role>Synthesized netlist containing tool version in header comments</role>
    </source>
  </data_sources>
  <format_hints>
    <hint format="SPEF">IEEE 1481 standard - version in *VERSION header with quoted string format</hint>
    <hint format="Netlist_Verilog">IEEE 1364/1800 - version typically in header comments with tool name and timestamp</hint>
    <hint format="STA_Log">Tool-specific format - may contain 'Reading SPEF file: <path>' or 'Generated on: <timestamp>' patterns</hint>
  </format_hints>
</semantic_intent>

<context_agent_data>
  <!-- ============================================ -->
  <!-- ğŸš¨ MANDATORY: ä»¥ä¸‹ class_constants å¿…é¡»åŸæ ·å¤åˆ¶ -->
  <!-- ç»å¯¹ç¦æ­¢: ç†è§£åé‡æ–°è¡¨è¾¾ã€ç®€åŒ–ã€æ”¹å†™              -->
  <!-- ============================================ -->
  <class_constants usage="MUST_COPY_VERBATIM">
    <found_desc>netlist/SPEF version metadata found</found_desc>
    <missing_desc>netlist/SPEF version metadata not found or pattern not satisfied</missing_desc>
    <waived_desc>version check waived for current flow stage</waived_desc>
    <found_reason>Version metadata extracted from {file_type}: {version_string}</found_reason>
    <missing_reason>Version metadata missing in {file_type} or pattern '{pattern}' not matched</missing_reason>
    <waived_base_reason>Version check waived: {waiver_name}</waived_base_reason>
    <extra_reason>Flow stage: {flow_step}, SPEF reading status: {spef_status}</extra_reason>
    <unused_waiver_reason>Waiver '{waiver_name}' defined but not applied (version metadata found)</unused_waiver_reason>
  </class_constants>
  <logic_steps>
    <step order="1">Parse STA log using data_verified patterns (read_netlist, Reading verilog netlist, Top level cell, flow_step, Skipping SPEF) to extract netlist file path, top-level cell name, flow stage, and SPEF skip status</step>
    <step order="2">CRITICAL: If netlist path found in STA log but file doesn't exist â†’ still count as 'found' (tool successfully processed it), add note='found in log, file not accessible', use status='Success' with relative_path field</step>
    <step order="3">CRITICAL: If SPEF reading was skipped (detected '[INFO] Skipping SPEF reading' in log) â†’ add item 'SPEF Reading was skipped: {reason}' to missing_items (NOT extra_items), extract skip reason from log message, this counts as a missing item affecting is_pass</step>
    <step order="4">If SPEF not skipped, parse SPEF file using standard_format patterns (*VERSION, *DESIGN, *DATE, *VENDOR, *PROGRAM per IEEE 1481) to extract version metadata; handle missing SPEF gracefully in synthesis stage</step>
    <step order="5">Parse netlist file header using standard_format patterns (// Generated by, // Date, module name per IEEE 1364/1800) to extract tool version and generation date; use defensive parsing for semantic_inference fields</step>
    <step order="6">CRITICAL: Parsing errors (e.g., 'Netlist path not found') â†’ add to extra_items (NOT missing_items), these are warnings that don't affect is_pass, skip errors already handled as missing items (e.g., SPEF skipped)</step>
    <step order="7">For Type 2/3: Search pattern_items (e.g., 'Generated on:*2025*') in extracted version strings using wildcard matching; count matches and compare against requirements.value threshold</step>
    <step order="8">For Type 3/4: Parse waive_items and match against flow stage or SPEF skip status; classify violations as waived (synthesis stage) or unwaived (post-route stage); apply [WAIVER] tag to waived violations in output</step>
  </logic_steps>
  <extraction_chain hint="æŒ‰æ­¤é¡ºåºè§£æå¯è·å¾—æœ€ä¼˜æ•ˆæœ">
    <parse_step order="1" source="chain">STA_Log, extract SPEF/netlist file paths, parse target files for version metadata, extract version string, validate against expected pattern</parse_step>
  </extraction_chain>
  <extraction_fields usage="ç›´æ¥ä½¿ç”¨è¿™äº›æ­£åˆ™æ¨¡å¼">
    <!-- source_type å«ä¹‰: -->
    <!-- data_verified: å·²éªŒè¯ï¼Œç›´æ¥ä½¿ç”¨ -->
    <!-- semantic_inference: æ¨æ–­çš„ï¼Œéœ€è¦ try-except -->
    <!-- standard_format: IEEE/EDA æ ‡å‡†ï¼Œæ·»åŠ æ ¼å¼æ£€æŸ¥ -->
    <file name="STA_Log" data_role="indirect_reference">
      <field name="netlist_file_path" confidence="100%" source="data_verified">
        <pattern><![CDATA[read_netlist\s+(\S+)]]></pattern>
        <purpose>Extracts the netlist file path from the read_netlist command, which is the primary source for netlis</purpose>
      </field>
      <field name="netlist_reading_path" confidence="100%" source="data_verified">
        <pattern><![CDATA[Reading verilog netlist '([^']+)']]></pattern>
        <purpose>Confirms the actual netlist file being read by the tool, provides validation of the file path</purpose>
      </field>
      <field name="top_level_cell" confidence="100%" source="data_verified">
        <pattern><![CDATA[Top level cell is (\w+)\.]]></pattern>
        <purpose>Identifies the top-level design module, useful for cross-referencing with netlist/SPEF metadata</purpose>
      </field>
      <field name="flow_step_name" confidence="100%" source="data_verified">
        <pattern><![CDATA[#@ flow_step:(\w+)]]></pattern>
        <purpose>Captures the current flow step, helps understand the context of the check (e.g., read_parasitics)</purpose>
      </field>
      <field name="spef_skipped_message" confidence="100%" source="data_verified">
        <pattern><![CDATA[\[INFO\]\s*Skipping SPEF reading(.+)]]></pattern>
        <purpose>Detects when SPEF reading is skipped, which affects whether SPEF version can be verified from this l</purpose>
      </field>
      <field name="netlist_unique_status" confidence="100%" source="data_verified">
        <pattern><![CDATA[\*\*\*\s*(Netlist is unique)\.]]></pattern>
        <purpose>Confirms netlist parsing completed successfully, indicates netlist is valid for version extraction</purpose>
      </field>
      <field name="spef_file_path" confidence="95%" source="standard_format">
        <pattern><![CDATA[read_spef\s+(\S+)]]></pattern>
        <purpose>Standard STA command for reading SPEF files, not present in sample but expected in typical STA logs</purpose>
      </field>
      <field name="generated_timestamp" confidence="80%" source="semantic_inference">
        <pattern><![CDATA[Generated on[:\s]+([^\n]+)]]></pattern>
        <purpose>Inferred from semantic intent mentioning 'Generated on:*2025*' pattern, though not present in curren</purpose>
      </field>
    </file>
    <file name="SPEF" data_role="direct_source">
      <field name="spef_version" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*VERSION\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 SPEF standard defines *VERSION header as primary version metadata field</purpose>
      </field>
      <field name="spef_design" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*DESIGN\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 standard - design name for cross-validation with netlist top-level cell</purpose>
      </field>
      <field name="spef_date" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*DATE\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 standard - generation timestamp, can be used to verify year (e.g., 2025)</purpose>
      </field>
      <field name="spef_vendor" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*VENDOR\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 standard - tool vendor information, part of version metadata</purpose>
      </field>
      <field name="spef_program" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*PROGRAM\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 standard - tool program name and version, primary source for tool version verification</purpose>
      </field>
      <field name="spef_standard" confidence="95%" source="standard_format">
        <pattern><![CDATA[\*SPEF\s+"([^"]+)"]]></pattern>
        <purpose>IEEE 1481 standard - SPEF format version (e.g., '1481-2009'), validates file format compliance</purpose>
      </field>
    </file>
    <file name="Netlist_Verilog" data_role="direct_source">
      <field name="netlist_tool_version" confidence="95%" source="standard_format">
        <pattern><![CDATA[//\s*Generated by[:\s]+([^\n]+)]]></pattern>
        <purpose>Standard Verilog netlist header comment containing tool name and version information</purpose>
      </field>
      <field name="netlist_generated_date" confidence="85%" source="semantic_inference">
        <pattern><![CDATA[//\s*Date[:\s]+([^\n]+)]]></pattern>
        <purpose>Common netlist header pattern for generation date, can verify year requirement (e.g., 2025)</purpose>
      </field>
      <field name="netlist_module_name" confidence="95%" source="standard_format">
        <pattern><![CDATA[module\s+(\w+)\s*[#(;]]]></pattern>
        <purpose>IEEE 1364/1800 standard - top module name for cross-validation with STA log top_level_cell</purpose>
      </field>
      <field name="netlist_version_comment" confidence="80%" source="semantic_inference">
        <pattern><![CDATA[//\s*Version[:\s]+([^\n]+)]]></pattern>
        <purpose>Inferred common pattern for version information in netlist header comments</purpose>
      </field>
    </file>
  </extraction_fields>
</context_agent_data>

# ğŸ“‹ ä»»åŠ¡

ç”Ÿæˆ Checker çš„æ ¸å¿ƒæ–¹æ³•:

| å±æ€§ | å€¼ |
|------|-----|
| Item ID | `IMP-10-0-0-00` |
| Class Name | `Check_10_0_0_00` |
| Module | `10.0_STA_DCD_CHECK` |
| Description | Confirm the netlist/spef version is correct. |

### æ£€æŸ¥ä¸Šä¸‹æ–‡
- **Item**: `IMP-10-0-0-00` (Check_10_0_0_00)
- **æè¿°**: Confirm the netlist/spef version is correct.
- **æ–‡ä»¶ç±»å‹**: Multi-format: STA_Log (primary trigger), SPEF (IEEE 1481 standard), Netlist_Verilog (IEEE 1364/1800 standard)
- **å‚è€ƒæ­£åˆ™**: `read_netlist\s+(\S+)` | `Reading verilog netlist '([^']+)'` | `Top level cell is (\w+)\.` | `#@ flow_step:(\w+)` | `\[INFO\]\s*Skipping SPEF reading(.+)` ... (+13 more)
- **æå–å­—æ®µ**: {'STA_Log': [{'field_name': 'netlist_file_path', 'search_pattern': 'read_netlist\\s+(\\S+)', 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Extracts the netlist file path from the read_netlist command, which is the primary source for netlist version verification', 'matched_line': '<CMD> read_netlist C:\\Users\\yuyin\\Desktop\\CHECKLIST\\IP_project_folder\\dbs\\phy_cmn_phase_align_digtop.v.gz'}, {'field_name': 'netlist_reading_path', 'search_pattern': "Reading verilog netlist '([^']+)'", 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Confirms the actual netlist file being read by the tool, provides validation of the file path', 'matched_line': "Reading verilog netlist 'C:\\Users\\yuyin\\Desktop\\CHECKLIST\\IP_project_folder\\dbs\\phy_cmn_phase_align_digtop.v.gz'"}, {'field_name': 'top_level_cell', 'search_pattern': 'Top level cell is (\\w+)\\.', 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Identifies the top-level design module, useful for cross-referencing with netlist/SPEF metadata', 'matched_line': 'Top level cell is phy_cmn_phase_align_digtop.'}, {'field_name': 'flow_step_name', 'search_pattern': '#@ flow_step:(\\w+)', 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Captures the current flow step, helps understand the context of the check (e.g., read_parasitics)', 'matched_line': '#@ flow_step:read_parasitics defined in /apps/ssg_tools/p4/nu_global/2025w39.2/common/steps.tcl at line 2758'}, {'field_name': 'spef_skipped_message', 'search_pattern': '\\[INFO\\]\\s*Skipping SPEF reading(.+)', 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Detects when SPEF reading is skipped, which affects whether SPEF version can be verified from this log', 'matched_line': '[INFO] Skipping SPEF reading as we are writing post-synthesis SDF files'}, {'field_name': 'netlist_unique_status', 'search_pattern': '\\*\\*\\*\\s*(Netlist is unique)\\.', 'data_type': 'str', 'source_type': 'data_verified', 'confidence': 1.0, 'rationale': 'Confirms netlist parsing completed successfully, indicates netlist is valid for version extraction', 'matched_line': '*** Netlist is unique.'}, {'field_name': 'spef_file_path', 'search_pattern': 'read_spef\\s+(\\S+)', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'Standard STA command for reading SPEF files, not present in sample but expected in typical STA logs', 'matched_line': None}, {'field_name': 'generated_timestamp', 'search_pattern': 'Generated on[:\\s]+([^\\n]+)', 'data_type': 'str', 'source_type': 'semantic_inference', 'confidence': 0.8, 'rationale': "Inferred from semantic intent mentioning 'Generated on:*2025*' pattern, though not present in current sample", 'matched_line': None}], 'SPEF': [{'field_name': 'spef_version', 'search_pattern': '\\*VERSION\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1481 SPEF standard defines *VERSION header as primary version metadata field', 'matched_line': None}, {'field_name': 'spef_design', 'search_pattern': '\\*DESIGN\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1481 standard - design name for cross-validation with netlist top-level cell', 'matched_line': None}, {'field_name': 'spef_date', 'search_pattern': '\\*DATE\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1481 standard - generation timestamp, can be used to verify year (e.g., 2025)', 'matched_line': None}, {'field_name': 'spef_vendor', 'search_pattern': '\\*VENDOR\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1481 standard - tool vendor information, part of version metadata', 'matched_line': None}, {'field_name': 'spef_program', 'search_pattern': '\\*PROGRAM\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1481 standard - tool program name and version, primary source for tool version verification', 'matched_line': None}, {'field_name': 'spef_standard', 'search_pattern': '\\*SPEF\\s+"([^"]+)"', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': "IEEE 1481 standard - SPEF format version (e.g., '1481-2009'), validates file format compliance", 'matched_line': None}], 'Netlist_Verilog': [{'field_name': 'netlist_tool_version', 'search_pattern': '//\\s*Generated by[:\\s]+([^\\n]+)', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'Standard Verilog netlist header comment containing tool name and version information', 'matched_line': None}, {'field_name': 'netlist_generated_date', 'search_pattern': '//\\s*Date[:\\s]+([^\\n]+)', 'data_type': 'str', 'source_type': 'semantic_inference', 'confidence': 0.85, 'rationale': 'Common netlist header pattern for generation date, can verify year requirement (e.g., 2025)', 'matched_line': None}, {'field_name': 'netlist_module_name', 'search_pattern': 'module\\s+(\\w+)\\s*[#(;]', 'data_type': 'str', 'source_type': 'standard_format', 'confidence': 0.95, 'rationale': 'IEEE 1364/1800 standard - top module name for cross-validation with STA log top_level_cell', 'matched_line': None}, {'field_name': 'netlist_version_comment', 'search_pattern': '//\\s*Version[:\\s]+([^\\n]+)', 'data_type': 'str', 'source_type': 'semantic_inference', 'confidence': 0.8, 'rationale': 'Inferred common pattern for version information in netlist header comments', 'matched_line': None}]}

<type_specifications hint="è¿è¡Œæ—¶æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©">
  <type id="1" needs_waiver="false">
    <pass_condition>version_found_in_netlist OR version_found_in_spef</pass_condition>
    <fail_condition>NOT version_found_in_netlist AND NOT version_found_in_spef</fail_condition>
  </type>
  <type id="2" needs_waiver="false">
    <pass_condition>all_patterns_matched AND match_count <= requirements.value</pass_condition>
    <fail_condition>NOT all_patterns_matched OR match_count > requirements.value</fail_condition>
  </type>
  <type id="3" needs_waiver="true">
    <pass_condition>all_violations_waived (e.g., synthesis stage waiver covers SPEF pattern mismatch)</pass_condition>
    <fail_condition>unwaived_violations_exist (e.g., post-route SPEF missing 2025 date)</fail_condition>
  </type>
  <type id="4" needs_waiver="true">
    <pass_condition>version_metadata_exists OR flow_stage_matches_waiver</pass_condition>
    <fail_condition>NOT version_metadata_exists AND NOT flow_stage_matches_waiver</fail_condition>
  </type>
</type_specifications>

<runtime_parameters hint="é‡è¦ï¼šå‚æ•°ä» self.item_data è·å–ï¼Œä¸æ˜¯ self.requirements">
  <pattern_items_usage types="Type2,Type3">
    <code_template><![CDATA[
# pattern_items ä» self.item_data è·å– (NOT self.requirements!)
requirements = self.item_data.get('requirements', {})
pattern_items = requirements.get('pattern_items', [])

# éå†åŒ¹é…ç¤ºä¾‹:
for item in pattern_items:
    if isinstance(item, str):
        pattern = item
    else:
        pattern = item.get('pattern', '')
    if pattern in extracted_value:
        matched = True
    ]]></code_template>
  </pattern_items_usage>
  <waive_items_usage types="Type3,Type4">
    <code_template><![CDATA[
# ä½¿ç”¨ WaiverHandlerMixin æä¾›çš„æ–¹æ³•
waivers = self.get_waivers()
waive_items_raw = waivers.get('waive_items', [])
waive_dict = self.parse_waive_items(waive_items_raw)

# åŒ¹é…åˆ¤æ–­ (åœ¨å¾ªç¯ä¸­ä½¿ç”¨):
for violation in violations:
    if self.match_waiver_entry(violation, waive_dict):
        waived_items.append(violation)
    else:
        unwaived_items.append(violation)
    ]]></code_template>
  </waive_items_usage>
</runtime_parameters>

# âš ï¸ CRITICAL: v2.0 ä¸‰å±‚æ¶æ„ - ä»£ç å¤ç”¨æ¨¡å¼

> **æ ¸å¿ƒåŸåˆ™: Type3/4 å¤ç”¨ Type2/1 çš„é€»è¾‘ï¼Œä¸è¦é‡å¤å®ç°ï¼**

## æ¶æ„è®¾è®¡

```
Layer 1: _parse_input_files()          # 4ä¸ªTypeå…±äº«ï¼Œè§£æä¸€æ¬¡
         â†“
Layer 2: å…±äº«é€»è¾‘æ¨¡å—                   # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
         - _boolean_check_logic()       # Type1/4 å…±äº« (å­˜åœ¨æ€§åˆ¤æ–­)
         - _pattern_check_logic()       # Type2/3 å…±äº« (æ­£åˆ™åŒ¹é…)
         â†“
Layer 3: _execute_typeN()              # ä½¿ç”¨æ¡†æ¶æ–¹æ³•
         - Type1: execute_boolean_check(parse_data_func, has_waiver=False)
         - Type2: execute_value_check(parse_data_func, has_waiver=False)
         - Type3: execute_value_check(parse_data_func, has_waiver=True)
         - Type4: execute_boolean_check(parse_data_func, has_waiver=True)
```

## æ¡†æ¶æ–¹æ³• API

> **Full API signatures are in System Prompt Section 2.3**

- `execute_boolean_check()` - Type 1/4: has_waiver=False/True
- `execute_value_check()` - Type 2/3: has_waiver=False/True, Type3éœ€è¦info_itemså‚æ•°

## ä»£ç æ¨¡æ¿

### Layer 2: å…±äº«é€»è¾‘æ¨¡å— (åœ¨ <helper_methods> ä¸­å®ç°)

```python
def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Boolean Check Logic (Type1/4 å…±äº«)
    
    æ ¸å¿ƒä¸šåŠ¡é€»è¾‘: æ£€æŸ¥é¡¹ç›®æ˜¯å¦å­˜åœ¨ (å­˜åœ¨æ€§åˆ¤æ–­)
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
    """
    # ä» parsed_data æå–æ•°æ®
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # ä¸šåŠ¡é€»è¾‘: åˆ¤æ–­æ˜¯å¦å­˜åœ¨
    # ... (å…·ä½“å®ç°)
    
    return found_items, missing_items, extra_items


def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Pattern Check Logic (Type2/3 å…±äº«)
    
    æ ¸å¿ƒä¸šåŠ¡é€»è¾‘: åŒ¹é… pattern_items (æ­£åˆ™åŒ¹é…)
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
    """
    # è·å– pattern_items
    requirements = self.item_data.get('requirements', {})
    pattern_items = requirements.get('pattern_items', [])
    
    # ä» parsed_data åŒ¹é…
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # ä¸šåŠ¡é€»è¾‘: æ­£åˆ™åŒ¹é…
    # ... (å…·ä½“å®ç°)
    
    return found_items, missing_items, extra_items
```

### Layer 3: _execute_typeN() ä½¿ç”¨æ¡†æ¶æ–¹æ³•

```python
def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 1: Boolean check - å­˜åœ¨å³ PASS"""
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Boolean Check Logic"""
        return self._boolean_check_logic(parsed_data)
    
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=False,
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 2: Value check - åŒ¹é… pattern_items"""
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Pattern Check Logic"""
        return self._pattern_check_logic(parsed_data)
    
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=False,
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 3: Value check with waiver - å¤ç”¨ Type2 é€»è¾‘"""
    # âš ï¸ å¤ç”¨ Type2 çš„é€»è¾‘æ¨¡å— (ä¸è¦é‡å¤å®ç°ï¼)
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Pattern Check Logic (ä¸Type2ç›¸åŒ)"""
        return self._pattern_check_logic(parsed_data)
    
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=True,  # Type3ç‰¹æœ‰: å¯ç”¨waiverå¤„ç†
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        extra_severity=Severity.FAIL,
        name_extractor=self._build_name_extractor()
    )


def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 4: Boolean check with waiver - å¤ç”¨ Type1 é€»è¾‘"""
    # âš ï¸ å¤ç”¨ Type1 çš„é€»è¾‘æ¨¡å— (ä¸è¦é‡å¤å®ç°ï¼)
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Boolean Check Logic (ä¸Type1ç›¸åŒ)"""
        return self._boolean_check_logic(parsed_data)
    
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=True,  # Type4ç‰¹æœ‰: å¯ç”¨waiverå¤„ç†
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )
```

### name_extractor è¾…åŠ©æ–¹æ³• (å¯é€‰)

```python
def _build_name_extractor(self):
    """è¿”å› name_extractor å‡½æ•°ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºåç§°"""
    def extract_name(name: str, metadata: Any) -> str:
        # æ ¹æ® metadata æ ¼å¼åŒ– name
        if isinstance(metadata, dict):
            if metadata.get('version'):
                return f"{name} (v{metadata['version']})"
            if metadata.get('path'):
                return f"{name}: {Path(metadata['path']).name}"
        return name
    return extract_name
```

## å®æ–½è¦æ±‚

1. **å¿…é¡»æå–å…±äº«æ¨¡å—**: å°† Boolean/Pattern åˆ¤æ–­é€»è¾‘æå–åˆ° `_boolean_check_logic()` å’Œ `_pattern_check_logic()`
2. **Type3/4 ç¦æ­¢é‡å¤å®ç°**: ç›´æ¥è°ƒç”¨å¯¹åº”çš„å…±äº«æ¨¡å—ï¼Œåªæ”¹å˜ `has_waiver` å‚æ•°
3. **ä½¿ç”¨æ¡†æ¶æ–¹æ³•**: `execute_boolean_check()` (Type1/4) å’Œ `execute_value_check()` (Type2/3)
4. **æ‰€æœ‰å…±äº«æ¨¡å—æ”¾åœ¨ <helper_methods>**: ç¡®ä¿å¯ä»¥è¢«æ‰€æœ‰ Type è°ƒç”¨

## ä¼˜åŠ¿

- **ä»£ç è¡Œæ•°å‡å°‘**: 357 lines (Golden 1242 â†’ v2.0 885)
- **é€»è¾‘ç»Ÿä¸€**: Type1/4 å…±äº« Boolean é€»è¾‘ï¼ŒType2/3 å…±äº« Pattern é€»è¾‘
- **æ¡†æ¶è‡ªåŠ¨å¤„ç†**: waiverå¤„ç†ã€found/missingåˆ†ç±»ã€outputæ„å»º
- **æ˜“äºç»´æŠ¤**: ä¿®æ”¹ä¸€æ¬¡ï¼Œ4ä¸ª Type åŒæ­¥æ›´æ–°


================================================================================
ğŸ“ CODE GENERATION TEMPLATES (Fillable Frameworks)
================================================================================

âš ï¸ CRITICAL: The following are **fillable frameworks** for methods you need to implement

Framework Instructions:
- FIXED: These sections MUST remain unchanged (API signatures, parameter passing)
- TODO: These sections need to be filled based on business logic
- âš ï¸ CRITICAL: Marks key constraints that MUST be followed

Please generate code strictly following the API signatures and parameters in the framework.
Do NOT omit any parameters or calls from FIXED sections!

======================================================================
LAYER 1: Input File Parsing
======================================================================


def _parse_input_files(self) -> Dict[str, Any]:
    """
    Parse input files to extract data for checking.
    
    Returns:
        Dict[str, Any] with structure:
        {
            'items': [...],  # or other business-relevant keys
            'metadata': {...},
            'errors': [...]
        }
    
    âš ï¸ CRITICAL: Return MUST be Dict, used by subsequent Type methods
    """
    # FIXED: Validate input files
    # IMPORTANT: validate_input_files() returns TUPLE: (valid_files, missing_files)
    valid_files, missing_files = self.validate_input_files()
    if not valid_files:
        raise ConfigurationError("No valid input files found")
    
    # TODO: Implement file parsing logic
    # Available template helpers:
    # - self.parse_log_with_patterns(file_path, patterns)
    # - self.normalize_command(text)
    
    # Example structure:
    result = {
        'items': [],  # TODO: Fill with actual parsed data
        'metadata': {'total': 0},
        'errors': []
    }
    
    # TODO: Parse each input file
    # for file_path in valid_files:
    #     with open(file_path, 'r', errors='ignore') as f:
    #         for line_num, line in enumerate(f, 1):
    #             # Parsing logic...
    #             pass
    
    return result


======================================================================
LAYER 2: Shared Logic Modules
======================================================================

## Boolean Check Logic (shared by Type1/4)


def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Boolean Check Logic (shared by Type1/4)
    
    Core Business Logic: Determine which items exist and which are missing
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
        - found_items: Dict[str, Dict] - key is item name, value is metadata
        - missing_items: Dict[str, Dict] - âš ï¸ MUST be Dict, NOT List
        - extra_items: Dict[str, Dict] - additionally discovered items
    
    âš ï¸ CRITICAL: All items MUST be in Dict[str, Dict] format:
    {
        'item_name': {
            'line_number': 123,  # REQUIRED for source tracking
            'file_path': '/path/to/file',  # REQUIRED
            'reason': 'Additional info'  # Optional
        }
    }
    """
    # TODO: Extract necessary data from parsed_data
    # Example structure:
    # items = parsed_data.get('items', [])
    # or
    # netlist_info = parsed_data.get('netlist_info', {})
    # spef_info = parsed_data.get('spef_info', {})
    
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # TODO: Implement business logic - determine found/missing
    # Example logic:
    # for item in items:
    #     if item['status'] == 'Success':
    #         found_items[item['name']] = {
    #             'line_number': item.get('line', 0),
    #             'file_path': item.get('file', ''),
    #             'reason': 'Found successfully'
    #         }
    #     else:
    #         missing_items[item['name']] = {
    #             'reason': f"Status: {item['status']}"
    #         }
    
    # âš ï¸ CRITICAL: Ensure returning Dict[str, Dict], not List!
    return found_items, missing_items, extra_items


## Pattern Check Logic (shared by Type2/3)


def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Pattern Check Logic (shared by Type2/3)
    
    Core Business Logic: Search for patterns in pattern_items
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
    """
    # FIXED: Get pattern_items
    requirements = self.item_data.get('requirements', {})
    pattern_items = requirements.get('pattern_items', [])
    
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # TODO: Extract content from parsed_data for searching
    # Example:
    # content = parsed_data.get('extracted_content', [])
    
    # TODO: Implement pattern matching logic
    # Example:
    # for pattern in pattern_items:
    #     matched = False
    #     for line in content:
    #         if self._match_pattern(line, [pattern]):
    #             found_items[pattern] = {
    #                 'line_number': line.get('line_num', 0),
    #                 'file_path': line.get('file', ''),
    #                 'matched': line.get('text', '')
    #             }
    #             matched = True
    #             break
    #     if not matched:
    #         missing_items[pattern] = {
    #             'reason': 'Pattern not found in input files'
    #         }
    
    return found_items, missing_items, extra_items


======================================================================
LAYER 3: Type Execution Methods
======================================================================

## Type 1: Boolean Check (no waiver)


def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """
    Type 1: Boolean check - Existence check, no waiver
    
    Business Logic: Check if certain items exist (e.g., files loaded successfully)
    Pass Condition: All required items exist
    Fail Condition: Any required item is missing
    """
    # FIXED: Type1/4 share Boolean Check Logic
    def parse_data():
        """Call shared Boolean Check Logic"""
        return self._boolean_check_logic(parsed_data)
    
    # FIXED: Type1 framework call signature
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=False,  # â† Type1 characteristic: no waiver
        found_desc=self.FOUND_DESC,  # â† Use class constant
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()  # â† Need to implement this helper
    )


## Type 2: Value Check (no waiver)


def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """
    Type 2: Value check - Pattern matching, no waiver
    
    Business Logic: Search for patterns in pattern_items
    Pass Condition: All patterns found
    Fail Condition: Any pattern not found
    """
    # FIXED: Type2/3 share Pattern Check Logic
    def parse_data():
        """Call shared Pattern Check Logic"""
        return self._pattern_check_logic(parsed_data)
    
    # FIXED: Type2 framework call signature
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=False,  # â† Type2 characteristic: no waiver
        found_desc="Pattern found",  # â† Customizable description
        missing_desc="Pattern not found",
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


## Type 3: Value Check with Waiver (has waiver)

âš ï¸ CRITICAL: Type3 is the MOST error-prone type!
MUST include info_items parameter, even if it's an empty dict.


def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """
    Type 3: Value check with waiver - Pattern matching + waiver support
    
    Business Logic: Same as Type2 (pattern search), but with waiver support
    Pass Condition: Pattern found OR waiver is valid
    Fail Condition: Pattern not found AND waiver is invalid/expired
    """
    # âš ï¸ CRITICAL: Type3 MUST prepare info_items (can be empty dict)
    # info_items are used to display informational entries (don't affect PASS/FAIL)
    # TODO: Build info_items based on parsed_data (if you need to display information)
    info_items = {}
    
    # Example: If you need to display file path information
    # netlist_info = parsed_data.get('netlist_info', {})
    # if netlist_info.get('path'):
    #     info_items['File Path'] = {
    #         'line_number': 0,
    #         'file_path': '',
    #         'reason': f"Found at: {netlist_info['path']}"
    #     }
    
    # FIXED: Type2/3 share Pattern Check Logic
    def parse_data():
        """Call shared Pattern Check Logic (same as Type2)"""
        return self._pattern_check_logic(parsed_data)
    
    # FIXED: Type3 framework call signature
    # âš ï¸ CRITICAL: Note the difference from Type2
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=True,  # â† Type3 characteristic: enable waiver
        info_items=info_items,  # â† Type3 characteristic: MUST include (can be empty)
        found_desc="Pattern found",
        missing_desc="Pattern not found",
        extra_desc=self.EXTRA_DESC,
        extra_severity=Severity.FAIL,  # â† Type3 characteristic: extra errors as FAIL
        name_extractor=self._build_name_extractor()
    )


## Type 4: Boolean Check with Waiver (has waiver)


def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """
    Type 4: Boolean check with waiver - Existence check + waiver support
    
    Business Logic: Same as Type1 (existence check), but with waiver support
    Pass Condition: Item exists OR waiver is valid
    Fail Condition: Item missing AND waiver is invalid/expired
    """
    # FIXED: Type1/4 share Boolean Check Logic
    def parse_data():
        """Call shared Boolean Check Logic (same as Type1)"""
        return self._boolean_check_logic(parsed_data)
    
    # FIXED: Type4 framework call signature
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=True,  # â† Type4 characteristic: enable waiver
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


================================================================================




## ğŸš¨ Critical Pattern Checklist

Before generating code, confirm the following patterns:

### Layer 1 (Parsing)
- [ ] `_parse_input_files()` returns `Dict[str, Any]`
- [ ] Returned Dict contains necessary keys (e.g., items, metadata, errors)
- [ ] Uses `valid_files, missing_files = self.validate_input_files()` (note: returns TUPLE)

### Layer 2 (Logic)
- [ ] `_boolean_check_logic(parsed_data)` returns `Tuple[Dict, Dict, Dict]`
- [ ] `_pattern_check_logic(parsed_data)` returns `Tuple[Dict, Dict, Dict]`
- [ ] **found_items, missing_items, extra_items MUST ALL be `Dict[str, Dict]`, NOT List**
- [ ] Each item's value MUST contain `line_number` and `file_path` keys

### Layer 3 (Execution)
- [ ] Type1: `execute_boolean_check(..., has_waiver=False)`
- [ ] Type2: `execute_value_check(..., has_waiver=False)`
- [ ] Type3: `execute_value_check(..., has_waiver=True, info_items={...})` â† **MUST include info_items**
- [ ] Type4: `execute_boolean_check(..., has_waiver=True)`
- [ ] All Types use `parse_data_func=lambda: ...` to wrap logic calls

### Common Patterns
- [ ] Class constants use `self.FOUND_DESC` etc.
- [ ] name_extractor uses `self._build_name_extractor()`
- [ ] Type3's extra_severity set to `Severity.FAIL`

### Data Structure Rules
```python
# âœ… CORRECT
missing_items["Item Name"] = {"reason": "..."}

# âŒ WRONG
missing_items.append("Item Name")
```


âš ï¸ Before submitting the generated code, please verify each item against the checklist above!


# ğŸ“¤ è¾“å‡ºè¦æ±‚

> **Full API contracts in System Prompt Section 2**

## âš ï¸ CRITICAL Reminders

1. **Method Signature**: `_execute_typeN(self, parsed_data)` - must accept parsed_data
2. **Helper Methods**: All `self._xxx()` calls must be defined in `<helper_methods>`
3. **Metadata Format**: Parse as `{'line_number': N, 'file_path': str}`, access as `meta.get('line_number', 0)`
4. **Waiver (Type3/4)**: Framework methods handle waiver automatically

## è¾“å‡º XML æ ¼å¼

```xml
<thoughts>
1. æ£€æŸ¥ç›®æ ‡ 2. æ•°æ®æµ 3. è¾…åŠ©æ–¹æ³•(å¤ç”¨Golden) 4. Pass/Failé€»è¾‘ 5. Metadataè¿½è¸ª
</thoughts>

<class_constants>
FOUND_DESC = "..." / MISSING_DESC = "..." / ...
</class_constants>

<parse_method>
def _parse_input_files(self) -> Dict[str, Any]: ...
</parse_method>

<execute_type1>...<execute_type2>...<execute_type3>...<execute_type4>

<helper_methods>
# âš ï¸ æ‰€æœ‰ self._xxx() è°ƒç”¨å¿…é¡»åœ¨è¿™é‡Œå®šä¹‰!
# âš ï¸ å¿…é¡»å®Œæ•´å¤ç”¨Goldençš„Helperæ–¹æ³•ï¼Œä¸è¦ç®€åŒ–!
</helper_methods>
```