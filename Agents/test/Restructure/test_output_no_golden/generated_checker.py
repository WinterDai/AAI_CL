# -*- coding: utf-8 -*-
"""
NetlistSpefVersionChecker.py - Checker Implementation for IMP-10-0-0-00

Description:
    Confirm the netlist/spef version is correct.

Author: CodeGen Agent
Created: 2026-01-03
Version: v1.0.0

This file was auto-generated by CodeGen Agent.
Manual modifications may be overwritten on regeneration.
"""


from pathlib import Path
import gzip
import re
import sys
from typing import List, Dict, Tuple, Optional, Any


# Add common module to path
_SCRIPT_DIR = Path(__file__).resolve().parent
# Navigate to CHECKLIST/CHECKLIST/Check_modules/common
_PROJECT_ROOT = _SCRIPT_DIR.parents[5]  # Go up to AAI_local/AAI/Main_Work/ACL
_COMMON_DIR = _PROJECT_ROOT / 'CHECKLIST' / 'CHECKLIST' / 'Check_modules' / 'common'
if str(_COMMON_DIR) not in sys.path:
    sys.path.insert(0, str(_COMMON_DIR))

# Framework imports
from base_checker import BaseChecker, CheckResult, ConfigurationError
from output_formatter import DetailItem, Severity, create_check_result
from checker_templates.waiver_handler_template import WaiverHandlerMixin
from checker_templates.output_builder_template import OutputBuilderMixin

from checker_templates.input_file_parser_template import InputFileParserMixin


# MANDATORY: Inherit mixins in correct order (InputFileParserMixin first if used)
class NetlistSpefVersionChecker(InputFileParserMixin, OutputBuilderMixin, WaiverHandlerMixin, BaseChecker):
    """
    IMP-10-0-0-00: Confirm the netlist/spef version is correct.
    
    Checking Types:
    - Type 1: requirements=N/A, pattern_items [], waivers=N/A/0 → Boolean Check
    - Type 2: requirements>0, pattern_items [...], waivers=N/A/0 → Value Check
    - Type 3: requirements>0, pattern_items [...], waivers>0 → Value Check with Waiver Logic
    - Type 4: requirements=N/A, pattern_items [], waivers>0 → Boolean Check with Waiver Logic
    
    Template Library v1.1.0:
    - Uses InputFileParserMixin for parsing (parse_log_with_patterns, normalize_command)
    - Uses WaiverHandlerMixin for waiver processing (parse_waive_items, match_waiver_entry)
    - Uses OutputBuilderMixin for result construction (build_complete_output)
    """
    
    # =========================================================================
    # UNIFIED DESCRIPTIONS - Class-level constants (LLM-Generated)
    # =========================================================================
    FOUND_DESC = "File successfully read with version information"
    MISSING_DESC = "File not found or version information missing"
    EXTRA_DESC = "Additional information or warnings"
    NETLIST_SUCCESS_REASON = "Netlist file read successfully"
    SPEF_SUCCESS_REASON = "SPEF file read successfully"
    NETLIST_MISSING_REASON = "Netlist file not found or read failed"
    SPEF_MISSING_REASON = "SPEF file not found or read failed"
    
    def __init__(self):
        """Initialize the checker."""
        super().__init__(
            check_module="IMP",
            item_id="IMP-10-0-0-00",
            item_desc="Confirm the netlist/spef version is correct."
        )
        # MANDATORY: Metadata tracking for debug (Golden pattern)
        # Used by helper methods to track line numbers for DetailItem
        self._metadata: Dict[str, Dict[str, Any]] = {}
        # Store parsed data
        self._parsed_items: List[Dict] = []
    
    # =========================================================================
    # Main Check Execution (Template - Fixed, v2.1 Golden-Aligned)
    # =========================================================================
    
    def execute_check(self) -> CheckResult:
        """
        Execute check with automatic type detection and delegation.
        
        v2.1: Aligned with Golden design pattern:
        1. Parse input files first via _parse_input_files()
        2. Pass parsed data to _execute_typeN(parsed_data)
        
        Returns:
            CheckResult based on detected checker type
        """
        try:
            if self.root is None:
                raise RuntimeError("Checker not initialized. Call init_checker() first.")
            
            # Parse input files first (Golden pattern)
            parsed_data = self._parse_input_files()
            
            # Detect checker type (use BaseChecker method)
            checker_type = self.detect_checker_type()
            
            # Execute based on type, passing parsed data
            if checker_type == 1:
                return self._execute_type1(parsed_data)
            elif checker_type == 2:
                return self._execute_type2(parsed_data)
            elif checker_type == 3:
                return self._execute_type3(parsed_data)
            else:  # checker_type == 4
                return self._execute_type4(parsed_data)
        except ConfigurationError as e:
            return e.check_result
    
    # =========================================================================
    # Input Parsing (LLM-Generated)
    # =========================================================================
    
    def _parse_input_files(self) -> Dict[str, Any]:
        """
        Parse input files to extract netlist and SPEF version information.
        
        Returns:
            Dict[str, Any] with structure:
            {
                'netlist_info': {
                    'status': 'Success'/'Not Found'/'Failed',
                    'path': '/absolute/path/to/netlist.v.gz',
                    'relative_path': '/path/from/log',  # if file not accessible
                    'version': '23.15-s099_1',
                    'date': 'Nov 18 2025'
                },
                'spef_info': {
                    'status': 'Success'/'Not Found'/'Skipped',
                    'path': '/absolute/path/to/spef.spef.gz',
                    'relative_path': '/path/from/log',
                    'version': '23.1.0-p075',
                    'date': 'Tue Jun 10 14:16:48 2025',
                    'skip_reason': 'reason if skipped'
                },
                'errors': []
            }
        """
        valid_files, missing_files = self.validate_input_files()
        if not valid_files:
            raise ConfigurationError("No valid input files found")
        
        result = {
            'netlist_info': {'status': 'Not Found'},
            'spef_info': {'status': 'Not Found'},
            'errors': []
        }
        
        # Initialize metadata storage
        self._metadata = {
            'netlist_success': {},
            'spef_step_end': {},
            'spef_skipped': {}
        }
        
        # Parse STA log to get file paths
        for file_path in valid_files:
            if file_path.suffix == '.log' or 'sta' in file_path.name.lower():
                sta_result = self._parse_sta_log(file_path)
                result['netlist_info'].update(sta_result.get('netlist_info', {}))
                result['spef_info'].update(sta_result.get('spef_info', {}))
                result['errors'].extend(sta_result.get('errors', []))
        
        # Parse actual netlist file if path found
        netlist_info = result['netlist_info']
        if netlist_info.get('path'):
            netlist_path = Path(netlist_info['path'])
            if netlist_path.exists():
                version_info = self._parse_netlist_version(netlist_path)
                netlist_info.update(version_info)
        
        # Parse actual SPEF file if path found
        spef_info = result['spef_info']
        if spef_info.get('path'):
            spef_path = Path(spef_info['path'])
            if spef_path.exists():
                version_info = self._parse_spef_version(spef_path)
                spef_info.update(version_info)
        
        return result
    
    # =========================================================================
    # Type 1: Boolean Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 1: Boolean check - 存在即 PASS"""
        def parse_data():
            """调用共享的Boolean Check Logic"""
            return self._boolean_check_logic(parsed_data)
        
        return self.execute_boolean_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 2: Value Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 2: Value check - Pattern matching, no waiver"""
        def parse_data():
            """调用共享的Pattern Check Logic"""
            return self._pattern_check_logic(parsed_data)
        
        return self.execute_value_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc="Pattern matched in version information",
            missing_desc="Pattern not found in version information",
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 3: Value Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 3: Value check with waiver - Pattern matching + waiver support"""
        # Prepare info_items for display
        info_items = {}
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        
        if netlist_info.get('path'):
            info_items['Netlist File Path'] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Found at: {netlist_info['path']}"
            }
        
        if spef_info.get('path'):
            info_items['SPEF File Path'] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Found at: {spef_info['path']}"
            }
        
        def parse_data():
            """调用共享的Pattern Check Logic"""
            return self._pattern_check_logic(parsed_data)
        
        return self.execute_value_check(
            parse_data_func=parse_data,
            has_waiver=True,
            info_items=info_items,
            found_desc="Pattern matched in version information",
            missing_desc="Pattern not found in version information",
            extra_desc=self.EXTRA_DESC,
            extra_severity=Severity.FAIL,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 4: Boolean Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """Type 4: Boolean check with waiver - Existence check + waiver support"""
        def parse_data():
            """调用共享的Boolean Check Logic"""
            return self._boolean_check_logic(parsed_data)
        
        return self.execute_boolean_check(
            parse_data_func=parse_data,
            has_waiver=True,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )

    # =========================================================================
    # Helper Methods (LLM-Generated)
    # =========================================================================
    
    def _build_name_extractor(self):
        """返回 name_extractor 函数，用于格式化输出"""
        def extract_name(name: str, metadata: Any) -> str:
            if isinstance(metadata, dict):
                version = metadata.get('version', '')
                date = metadata.get('date', '')
                path = metadata.get('path', '')
                
                parts = [name]
                if path:
                    parts.append(f"Path: {path}")
                if version:
                    parts.append(f"Version: {version}")
                if date:
                    parts.append(f"Date: {date}")
                
                return ", ".join(parts)
            return name
        return extract_name

    def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Boolean Check Logic (Type1/4 共享)
        
        核心业务逻辑：检查 netlist 和 SPEF 文件是否成功读取
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Check netlist
        netlist_status = netlist_info.get('status', 'Not Found')
        if netlist_status == 'Success':
            if netlist_info.get('path'):
                # 文件存在且可读
                metadata = self._metadata.get('netlist_success', {})
                found_items["Netlist File"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': netlist_info.get('version', 'Unknown'),
                    'date': netlist_info.get('date', ''),
                    'path': netlist_info.get('path', 'Unknown')
                }
            elif netlist_info.get('relative_path'):
                # 路径存在但文件不可访问 → 仍算found（因为status='Success'）
                metadata = self._metadata.get('netlist_success', {})
                found_items["Netlist File"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'note': 'found in log, file not accessible',
                    'path': netlist_info['relative_path']
                }
        else:
            missing_items["Netlist File"] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Status: {netlist_status}"
            }
        
        # Check SPEF
        spef_status = spef_info.get('status', 'Not Found')
        if spef_status == 'Success':
            if spef_info.get('path'):
                metadata = self._metadata.get('spef_step_end', {})
                found_items["SPEF File"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': spef_info.get('version', 'Unknown'),
                    'date': spef_info.get('date', ''),
                    'path': spef_info.get('path', 'Unknown')
                }
            elif spef_info.get('relative_path'):
                metadata = self._metadata.get('spef_step_end', {})
                found_items["SPEF File"] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'note': 'found in log, file not accessible',
                    'path': spef_info['relative_path']
                }
        elif spef_status == 'Skipped':
            # SPEF跳过 → missing_items (影响is_pass)
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            missing_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        else:
            missing_items["SPEF File"] = {
                'line_number': 0,
                'file_path': '',
                'reason': f"Status: {spef_status}"
            }
        
        # 错误作为extra_items (不影响is_pass)
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                extra_items[f"Error: {error}"] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': 'Unexpected error during parsing'
                }
        
        return found_items, missing_items, extra_items


    def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Pattern Check Logic (Type2/3 共享)
        
        核心业务逻辑：在版本信息中匹配 pattern_items
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        requirements = self.item_data.get('requirements', {})
        pattern_items = requirements.get('pattern_items', [])
        
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Build searchable content
        searchable_content = []
        
        # Add netlist version info
        if netlist_info.get('version'):
            searchable_content.append({
                'text': f"Netlist Version: {netlist_info['version']}",
                'source': 'netlist',
                'metadata': netlist_info
            })
        if netlist_info.get('date'):
            searchable_content.append({
                'text': f"Netlist Date: {netlist_info['date']}",
                'source': 'netlist',
                'metadata': netlist_info
            })
        
        # Add SPEF version info
        if spef_info.get('version'):
            searchable_content.append({
                'text': f"SPEF Version: {spef_info['version']}",
                'source': 'spef',
                'metadata': spef_info
            })
        if spef_info.get('date'):
            searchable_content.append({
                'text': f"SPEF Date: {spef_info['date']}",
                'source': 'spef',
                'metadata': spef_info
            })
        
        # Match patterns
        for pattern in pattern_items:
            if isinstance(pattern, dict):
                pattern_str = pattern.get('pattern', '')
            else:
                pattern_str = str(pattern)
            
            matched = False
            for content_item in searchable_content:
                if pattern_str.lower() in content_item['text'].lower():
                    source = content_item['source']
                    metadata = content_item['metadata']
                    
                    found_items[pattern_str] = {
                        'line_number': 0,
                        'file_path': metadata.get('path', ''),
                        'matched': content_item['text'],
                        'source': source,
                        'version': metadata.get('version', ''),
                        'date': metadata.get('date', '')
                    }
                    matched = True
                    break
            
            if not matched:
                missing_items[pattern_str] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': 'Pattern not found in version information'
                }
        
        # Check SPEF skip status - add as extra_item if skipped (Type2/3)
        if spef_info.get('status') == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            extra_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        
        return found_items, missing_items, extra_items


    def _parse_sta_log(self, sta_log: Path) -> Dict[str, Any]:
        """
        解析 STA log 文件，提取 netlist 和 SPEF 路径及状态
        
        Returns:
            Dict with netlist_info, spef_info, errors
        """
        result = {
            'netlist_info': {'status': 'Not Found'},
            'spef_info': {'status': 'Not Found'},
            'errors': []
        }
        
        try:
            with open(sta_log, 'r', errors='ignore') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # Extract netlist path
                    if 'read_netlist' in line.lower() or 'reading verilog netlist' in line.lower():
                        match = re.search(r"['\"]([^'\"]+\.v(?:\.gz)?)['\"]", line)
                        if not match:
                            match = re.search(r'(\S+\.v(?:\.gz)?)', line)
                        
                        if match:
                            netlist_path_str = match.group(1)
                            netlist_path = Path(netlist_path_str)
                            if netlist_path.exists():
                                result['netlist_info']['path'] = str(netlist_path.resolve())
                            else:
                                # Path found but file doesn't exist → save as relative_path
                                result['netlist_info']['relative_path'] = netlist_path_str
                    
                    # Netlist success indicator
                    elif '*** netlist is unique' in line.lower() or 'netlist is unique' in line.lower():
                        result['netlist_info']['status'] = 'Success'
                        self._metadata['netlist_success'] = {
                            'line_number': line_num,
                            'file_path': str(sta_log)
                        }
                    
                    # Extract SPEF path
                    elif 'read spef' in line.lower() or 'read_parasitics' in line.lower():
                        match = re.search(r"['\"]([^'\"]+\.spef(?:\.gz)?)['\"]", line)
                        if not match:
                            match = re.search(r'(\S+\.spef(?:\.gz)?)', line)
                        
                        if match:
                            spef_path_str = match.group(1)
                            spef_path = Path(spef_path_str)
                            if spef_path.exists():
                                result['spef_info']['path'] = str(spef_path.resolve())
                            else:
                                result['spef_info']['relative_path'] = spef_path_str
                    
                    # SPEF success indicator
                    elif 'end flow_step read_parasitics' in line.lower():
                        result['spef_info']['status'] = 'Success'
                        self._metadata['spef_step_end'] = {
                            'line_number': line_num,
                            'file_path': str(sta_log)
                        }
                    
                    # SPEF skip indicator
                    elif 'skipping spef reading' in line.lower():
                        result['spef_info']['status'] = 'Skipped'
                        result['spef_info']['skip_reason'] = line
                        self._metadata['spef_skipped'] = {
                            'line_number': line_num,
                            'file_path': str(sta_log)
                        }
        
        except Exception as e:
            result['errors'].append(f"Error parsing STA log: {str(e)}")
        
        return result


    def _parse_netlist_version(self, netlist_path: Path) -> Dict[str, str]:
        """
        解析 netlist 文件提取版本信息
        
        Returns:
            Dict with 'version' and 'date' keys
        """
        version_info = {}
        
        try:
            # Read first 100 lines for version info
            with open(netlist_path, 'r', errors='ignore') as f:
                for i, line in enumerate(f):
                    if i >= 100:
                        break
                    
                    # Match: Generated by Cadence Genus(TM) Synthesis Solution 23.15-s099_1
                    if 'genus' in line.lower() and 'synthesis' in line.lower():
                        match = re.search(r'(\d+\.\d+[-\w]+)', line)
                        if match:
                            version_info['version'] = match.group(1)
                    
                    # Match: Generated on: Nov 18 2025 15:58:15
                    if 'generated on' in line.lower():
                        match = re.search(r':\s*([A-Za-z]+\s+\d+\s+\d{4})', line)
                        if match:
                            version_info['date'] = match.group(1)
                    
                    if 'version' in version_info and 'date' in version_info:
                        break
        
        except Exception as e:
            pass
        
        return version_info


    def _parse_spef_version(self, spef_path: Path) -> Dict[str, str]:
        """
        解析 SPEF 文件提取版本信息
        
        Returns:
            Dict with 'version' and 'date' keys
        """
        version_info = {}
        
        try:
            # Read first 50 lines for header info
            with open(spef_path, 'r', errors='ignore') as f:
                for i, line in enumerate(f):
                    if i >= 50:
                        break
                    
                    # Match: *DATE "Tue Jun 10 14:16:48 2025"
                    if line.startswith('*DATE'):
                        match = re.search(r'"([^"]+)"', line)
                        if match:
                            version_info['date'] = match.group(1)
                    
                    # Match: *VERSION "23.1.0-p075 Tue Sep 26 09:27:40 PDT 2023"
                    if line.startswith('*VERSION'):
                        match = re.search(r'"([^"]+)"', line)
                        if match:
                            full_version = match.group(1)
                            # Extract version number
                            version_match = re.search(r'(\d+\.\d+\.\d+[-\w]+)', full_version)
                            if version_match:
                                version_info['version'] = version_match.group(1)
                    
                    if 'version' in version_info and 'date' in version_info:
                        break
        
        except Exception as e:
            pass
        
        return version_info


# ============================================================================
# Entry Point (Template - Fixed, Golden-Aligned)
# ============================================================================

def init_checker() -> NetlistSpefVersionChecker:
    """Initialize and return the checker instance."""
    checker = NetlistSpefVersionChecker()
    checker.init_checker()
    return checker


if __name__ == '__main__':
    checker = init_checker()
    checker.execute_check()
    checker.write_output()
