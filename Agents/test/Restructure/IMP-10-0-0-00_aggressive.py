################################################################################
# Script Name: IMP-10-0-0-00_aggressive.py
#
# AGGRESSIVE REFACTORING VERSION
# ==============================
# This version demonstrates the aggressive refactoring approach where:
# - Type 1/2/3/4 methods are reduced to 30-60 lines of business logic
# - Framework handles all common execution flow (found/missing classification, waiver, output)
# - LLM only needs to focus on parse_data_func
#
# Purpose:
#   Confirm the netlist/spef version is correct.
#   Parse STA log to find netlist/SPEF files, then extract version information
#   from actual files.
#
# Auto Type Detection:
#   Type 1: requirements.value=N/A, waivers.value=N/A/0 → Boolean check
#   Type 2: requirements.value>0, pattern_items exists, waivers.value=N/A/0 → Value comparison
#   Type 3: requirements.value>0, pattern_items exists, waivers.value>0 → Value with waiver logic
#   Type 4: requirements.value=N/A, waivers.value>0 → Boolean with waiver logic
#
# Author: yyin (Aggressive Refactoring)
# Date: 2026-01-02
################################################################################

from pathlib import Path
import re
import sys
import gzip
from typing import List, Dict, Tuple, Optional, Any


# Add common module to path
_SCRIPT_DIR = Path(__file__).resolve().parent
_CHECK_MODULES_DIR = _SCRIPT_DIR / 'Check_modules'
_COMMON_DIR = _CHECK_MODULES_DIR / 'common'
if str(_COMMON_DIR) not in sys.path:
    sys.path.insert(0, str(_COMMON_DIR))

from base_checker import BaseChecker, CheckResult, ConfigurationError
from output_formatter import DetailItem, Severity, create_check_result
from checker_templates.waiver_handler_template import WaiverHandlerMixin
from checker_templates.output_builder_template import OutputBuilderMixin


class NetlistSpefVersionChecker(BaseChecker, WaiverHandlerMixin, OutputBuilderMixin):
    """
    AGGRESSIVE REFACTORING VERSION
    ==============================
    Uses the new execute_boolean_check() and execute_value_check() framework methods.
    LLM only needs to generate business logic in parse_data_func.
    """
    
    def __init__(self):
        super().__init__(
            check_module="10.0_STA_DCD_CHECK",
            item_id="IMP-10-0-0-00",
            item_desc="Confirm the netlist/spef version is correct"
        )
        self._metadata: Dict[str, Dict[str, Any]] = {}
        self._netlist_info: Dict[str, Any] = {}
        self._spef_info: Dict[str, Any] = {}
        self._sta_log_info: Dict[str, Any] = {}
    
    def _read_file_content(self, file_path: Path, max_lines: int = 100) -> List[str]:
        """Read file content, supporting both plain text and gzip compressed files."""
        if not file_path.exists():
            return []
        
        try:
            if file_path.suffix == '.gz':
                try:
                    with gzip.open(file_path, 'rt', encoding='utf-8', errors='ignore') as f:
                        return [line for i, line in enumerate(f) if i < max_lines]
                except (gzip.BadGzipFile, OSError):
                    pass
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                return [line for i, line in enumerate(f) if i < max_lines]
        except Exception as e:
            print(f"Warning: Failed to read {file_path}: {e}")
            return []
    
    def _parse_netlist_version(self, netlist_path: Path) -> Dict[str, str]:
        """Parse netlist file to extract version information."""
        version_info = {
            'tool': '', 'version': '', 'date': '', 'time': '', 'full_timestamp': ''
        }
        
        if not netlist_path.exists():
            return version_info
        
        lines = self._read_file_content(netlist_path, max_lines=50)
        
        for line in lines:
            if 'Generated by' in line and 'Genus' in line:
                match = re.search(r'Synthesis Solution\s+([\d\.\-\w]+)', line)
                if match:
                    version_info['tool'] = 'Cadence Genus Synthesis Solution'
                    version_info['version'] = match.group(1)
            
            elif 'Generated on:' in line:
                match = re.search(r'Generated on:\s+(\w+\s+\d+\s+\d+)\s+([\d:]+)', line)
                if match:
                    version_info['date'] = match.group(1)
                    version_info['time'] = match.group(2)
                    version_info['full_timestamp'] = f"{match.group(1)} {match.group(2)}"
        
        return version_info
    
    def _parse_spef_version(self, spef_path: Path) -> Dict[str, str]:
        """Parse SPEF file to extract version information."""
        version_info = {
            'design': '', 'date': '', 'vendor': '', 'program': '', 'version': '', 'spef_standard': ''
        }
        
        if not spef_path.exists():
            return version_info
        
        lines = self._read_file_content(spef_path, max_lines=100)
        
        for line in lines:
            if line.startswith('*SPEF'):
                match = re.search(r'\*SPEF\s+"([^"]+)"', line)
                if match:
                    version_info['spef_standard'] = match.group(1)
            elif line.startswith('*DESIGN'):
                match = re.search(r'\*DESIGN\s+"([^"]+)"', line)
                if match:
                    version_info['design'] = match.group(1)
            elif line.startswith('*DATE'):
                match = re.search(r'\*DATE\s+"([^"]+)"', line)
                if match:
                    version_info['date'] = match.group(1)
            elif line.startswith('*VENDOR'):
                match = re.search(r'\*VENDOR\s+"([^"]+)"', line)
                if match:
                    version_info['vendor'] = match.group(1)
            elif line.startswith('*PROGRAM'):
                match = re.search(r'\*PROGRAM\s+"([^"]+)"', line)
                if match:
                    version_info['program'] = match.group(1)
            elif line.startswith('*VERSION'):
                match = re.search(r'\*VERSION\s+"([^"]+)"', line)
                if match:
                    version_info['version'] = match.group(1)
        
        return version_info
    
    def _resolve_relative_path(self, relative_path: str, sta_log_dir: Path) -> Optional[Path]:
        """Resolve relative path from STA log to absolute path."""
        if not relative_path:
            return None
        
        try:
            clean_path = relative_path.strip().strip('"').strip("'")
            abs_path = (sta_log_dir / clean_path).resolve()
            
            if abs_path.exists():
                return abs_path
            
            if self.root:
                abs_path = (self.root / clean_path).resolve()
                if abs_path.exists():
                    return abs_path
        except Exception as e:
            print(f"Warning: Failed to resolve path {relative_path}: {e}")
        
        return None
    
    def _parse_sta_log(self) -> Dict[str, Any]:
        """Parse STA log file to extract netlist/SPEF information."""
        sta_info = {
            'netlist_path': None,
            'netlist_status': 'Not Found',
            'spef_path': None,
            'spef_status': 'Not Found',
            'errors': [],
            'warnings': []
        }
        
        if not self.item_data or 'input_files' not in self.item_data:
            raise ConfigurationError("No input_files specified in configuration")
        
        input_files = self.item_data['input_files']
        if not input_files:
            raise ConfigurationError("input_files is empty in configuration")
        
        if isinstance(input_files, str):
            input_files = [input_files]
        
        for file_path_str in input_files:
            file_path = Path(file_path_str)
            
            if not file_path.exists():
                sta_info['errors'].append(f"STA log file not found: {file_path_str}")
                continue
            
            sta_log_dir = file_path.parent
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                if 'read_netlist' in line and '<CMD>' in line:
                    match = re.search(r'read_netlist\s+(\S+)', line)
                    if match:
                        netlist_rel_path = match.group(1)
                        netlist_abs_path = self._resolve_relative_path(netlist_rel_path, sta_log_dir)
                        if netlist_abs_path:
                            sta_info['netlist_path'] = netlist_abs_path
                        else:
                            sta_info['netlist_relative_path'] = netlist_rel_path
                        
                        self._metadata['netlist_cmd'] = {
                            'line_number': line_num,
                            'file_path': str(file_path),
                            'relative_path': netlist_rel_path
                        }
                
                elif 'Reading verilog netlist' in line:
                    match = re.search(r"Reading verilog netlist\s+'([^']+)'", line)
                    if match:
                        netlist_rel_path = match.group(1)
                        if not sta_info.get('netlist_path'):
                            netlist_abs_path = self._resolve_relative_path(netlist_rel_path, sta_log_dir)
                            if netlist_abs_path:
                                sta_info['netlist_path'] = netlist_abs_path
                            else:
                                sta_info['netlist_relative_path'] = netlist_rel_path
                    
                    self._metadata['netlist_reading'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                elif '*** Netlist is unique' in line or 'Netlist is unique' in line:
                    sta_info['netlist_status'] = 'Success'
                    self._metadata['netlist_success'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                elif 'Skipping SPEF reading' in line:
                    sta_info['spef_status'] = 'Skipped'
                    sta_info['errors'].append("SPEF reading was skipped")
                    self._metadata['spef_skipped'] = {
                        'line_number': line_num,
                        'file_path': str(file_path),
                        'reason': line.strip()
                    }
                
                elif 'Begin flow_step read_parasitics' in line:
                    self._metadata['spef_step_begin'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                elif 'End flow_step read_parasitics' in line:
                    self._metadata['spef_step_end'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                    if sta_info['spef_status'] != 'Skipped':
                        sta_info['spef_status'] = 'Success'
                
                elif 'read_spef' in line.lower() or 'read_parasitics' in line.lower():
                    match = re.search(r'([\w/\.\-]+\.spef(?:\.gz)?)', line, re.IGNORECASE)
                    if match:
                        spef_rel_path = match.group(1)
                        spef_abs_path = self._resolve_relative_path(spef_rel_path, sta_log_dir)
                        if spef_abs_path:
                            sta_info['spef_path'] = spef_abs_path
                
                elif re.search(r'\b(error|failed)\b', line, re.IGNORECASE):
                    if 'netlist' in line.lower() or 'spef' in line.lower():
                        sta_info['errors'].append(f"Line {line_num}: {line.strip()}")
        
        if sta_info.get('netlist_relative_path') or sta_info.get('netlist_path'):
            if 'netlist_success' in self._metadata:
                sta_info['netlist_status'] = 'Success'
            elif sta_info['netlist_status'] == 'Not Found':
                sta_info['netlist_status'] = 'Read Command Found'
        
        return sta_info
    
    def _parse_input_files(self) -> Tuple[Dict[str, Any], Dict[str, Any], List[str]]:
        """Parse input files to extract netlist and SPEF version information."""
        self._sta_log_info = self._parse_sta_log()
        
        netlist_info = {}
        spef_info = {}
        errors = list(self._sta_log_info.get('errors', []))
        
        if self._sta_log_info.get('netlist_path'):
            netlist_path = self._sta_log_info['netlist_path']
            netlist_info = self._parse_netlist_version(netlist_path)
            netlist_info['path'] = str(netlist_path)
            netlist_info['status'] = self._sta_log_info.get('netlist_status', 'Unknown')
            
            if not netlist_info.get('version'):
                errors.append(f"Failed to extract version from netlist: {netlist_path.name}")
        elif self._sta_log_info.get('netlist_relative_path'):
            netlist_info['relative_path'] = self._sta_log_info['netlist_relative_path']
            netlist_info['status'] = self._sta_log_info.get('netlist_status', 'Unknown')
            netlist_info['note'] = 'File path found in log but actual file not accessible'
        else:
            errors.append("Netlist file path not found in STA log")
        
        if self._sta_log_info.get('spef_path'):
            spef_path = self._sta_log_info['spef_path']
            spef_info = self._parse_spef_version(spef_path)
            spef_info['path'] = str(spef_path)
            spef_info['status'] = self._sta_log_info.get('spef_status', 'Unknown')
            
            if not spef_info.get('version'):
                errors.append(f"Failed to extract version from SPEF: {spef_path.name}")
        else:
            spef_status = self._sta_log_info.get('spef_status', 'Not Found')
            spef_info['status'] = spef_status
            if spef_status == 'Skipped':
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = metadata.get('reason', 'SPEF reading was skipped')
                skip_reason = skip_reason.replace('[INFO] ', '')
                spef_info['skip_reason'] = skip_reason
            elif spef_status == 'Not Found':
                if 'spef_step_end' not in self._metadata:
                    errors.append("SPEF file path not found in STA log")
        
        return netlist_info, spef_info, errors
    
    def _match_pattern(self, text: str, patterns: List[str]) -> Optional[str]:
        """Check if text matches any pattern."""
        for pattern in patterns:
            try:
                regex_pattern = pattern
                if '*' in pattern and not pattern.startswith('^'):
                    regex_pattern = pattern.replace('*', '.*')
                
                if re.search(regex_pattern, text, re.IGNORECASE):
                    return pattern
            except re.error:
                if pattern.lower() in text.lower():
                    return pattern
        return None
    
    # =========================================================================
    # AGGRESSIVE REFACTORING: Type Methods (30-60 lines each)
    # =========================================================================
    
    def _execute_type1(self, netlist_info: Dict[str, Any], spef_info: Dict[str, Any], 
                       errors: List[str]) -> CheckResult:
        """
        Type 1: Boolean check (LLM只需生成parse_data逻辑)
        """
        def parse_data():
            """LLM生成的业务逻辑：检查netlist/SPEF文件是否成功加载"""
            found_items = {}
            missing_items = {}
            extra_items = {}
            
            # Check netlist
            netlist_status = netlist_info.get('status', 'Not Found')
            if netlist_status == 'Success':
                netlist_path = netlist_info.get('path', 'Unknown')
                version_str = netlist_info.get('version', 'Unknown')
                date_str = netlist_info.get('full_timestamp', netlist_info.get('date', 'Unknown'))
                
                metadata = self._metadata.get('netlist_success', {})
                found_items['Netlist File'] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': netlist_path
                }
            else:
                missing_items['Netlist File'] = {
                    'note': f'Netlist status: {netlist_status}'
                }
            
            # Check SPEF
            spef_status = spef_info.get('status', 'Not Found')
            if spef_status == 'Success':
                spef_path = spef_info.get('path', 'Unknown')
                version_str = spef_info.get('version', 'Unknown')
                date_str = spef_info.get('date', 'Unknown')
                
                metadata = self._metadata.get('spef_step_end', {})
                found_items['SPEF File'] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': spef_path
                }
            elif spef_status == 'Skipped':
                # SPEF skip is extra_item (not missing_item)
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
                extra_items["SPEF Reading was skipped"] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'reason': skip_reason
                }
            else:
                missing_items['SPEF File'] = {
                    'note': f'SPEF status: {spef_status}'
                }
            
            # Add other errors
            for error in errors:
                if "SPEF reading was skipped" not in error:
                    extra_items[f"Error: {error}"] = {
                        'reason': 'Unexpected error'
                    }
            
            return found_items, missing_items, extra_items
        
        # Framework自动处理found/missing/waiver/output
        name_extractor = self._build_name_extractor()
        return self.execute_boolean_check(
            parse_data,
            has_waiver=False,
            default_file='N/A',
            name_extractor=name_extractor,
            found_reason="File successfully loaded",
            missing_reason="File not loaded",
            extra_reason="Design has no spef/netlist file or unexpected error",
            found_desc="Netlist/SPEF files are loaded",
            missing_desc="Netlist/SPEF files are not loaded",
            extra_desc="Design has no spef/netlist file"
        )
    
    def _execute_type2(self, netlist_info: Dict[str, Any], spef_info: Dict[str, Any], 
                       errors: List[str]) -> CheckResult:
        """
        Type 2: Value check (LLM只需生成parse_data逻辑)
        """
        def parse_data():
            """LLM生成的业务逻辑：收集版本信息并匹配pattern_items"""
            # 获取pattern_items配置
            requirements = self.get_requirements()
            pattern_items = requirements.get('pattern_items', []) if requirements else []
            
            # 收集所有版本信息内容
            all_content = []
            if netlist_info.get('tool'):
                all_content.append(f"Tool: {netlist_info['tool']}")
            if netlist_info.get('version'):
                all_content.append(f"Genus Synthesis Solution {netlist_info['version']}")
            if netlist_info.get('full_timestamp'):
                all_content.append(f"Generated on: {netlist_info['full_timestamp']}")
            
            if spef_info.get('program'):
                all_content.append(f"Program: {spef_info['program']}")
            if spef_info.get('version'):
                all_content.append(f"VERSION {spef_info['version']}")
            if spef_info.get('date'):
                all_content.append(f"DATE {spef_info['date']}")
            
            # 匹配patterns
            found_items = {}
            missing_items = {}
            matched_patterns = set()
            
            for pattern in pattern_items:
                found = False
                matched_content = None
                for content in all_content:
                    if self._match_pattern(content, [pattern]):
                        found = True
                        matched_content = content
                        break
                
                if found:
                    matched_patterns.add(pattern)
                    # 确定metadata来源
                    if 'Genus' in pattern or 'Generated on' in pattern:
                        metadata = self._metadata.get('netlist_success', {})
                    elif 'Quantus' in pattern or 'DATE' in pattern or 'VERSION' in pattern:
                        metadata = self._metadata.get('spef_step_end', {})
                    else:
                        metadata = {}
                    
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', ''),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
            
            # 找出未匹配的patterns
            missing_items = {p: {} for p in pattern_items if p not in matched_patterns}
            
            # 处理extra_items（SPEF skip等）
            extra_items = {}
            if spef_info.get('status') == 'Skipped':
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
                extra_items["SPEF Reading was skipped"] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'reason': skip_reason
                }
            
            # Add other errors
            for error in errors:
                if "SPEF reading was skipped" not in error:
                    extra_items[f"Error: {error}"] = {
                        'reason': 'Unexpected error'
                    }
            
            return found_items, missing_items, extra_items
        
        # Framework自动处理pattern匹配、waiver、output
        name_extractor = self._build_name_extractor()
        return self.execute_value_check(
            parse_data,
            has_waiver=False,
            default_file='N/A',
            name_extractor=name_extractor,
            found_reason="Version pattern matched",
            missing_reason="Required pattern not found",
            extra_reason="Design has no spef/netlist file or unexpected error",
            found_desc="Netlist/SPEF version is correct",
            missing_desc="Netlist/SPEF version isn't correct",
            extra_desc="Design has no spef/netlist file"
        )
    
    def _execute_type3(self, netlist_info: Dict[str, Any], spef_info: Dict[str, Any], 
                       errors: List[str]) -> CheckResult:
        """
        Type 3: Value check with waiver (LLM只需生成parse_data逻辑)
        """
        def parse_data():
            """LLM生成的业务逻辑：与Type2相同，Framework自动处理waiver"""
            requirements = self.get_requirements()
            pattern_items = requirements.get('pattern_items', []) if requirements else []
            
            all_content = []
            if netlist_info.get('tool'):
                all_content.append(f"Tool: {netlist_info['tool']}")
            if netlist_info.get('version'):
                all_content.append(f"Genus Synthesis Solution {netlist_info['version']}")
            if netlist_info.get('full_timestamp'):
                all_content.append(f"Generated on: {netlist_info['full_timestamp']}")
            
            if spef_info.get('program'):
                all_content.append(f"Program: {spef_info['program']}")
            if spef_info.get('version'):
                all_content.append(f"VERSION {spef_info['version']}")
            if spef_info.get('date'):
                all_content.append(f"DATE {spef_info['date']}")
            
            found_items = {}
            missing_items = {}
            for pattern in pattern_items:
                found = False
                matched_content = None
                for content in all_content:
                    if self._match_pattern(content, [pattern]):
                        found = True
                        matched_content = content
                        break
                
                if found:
                    if 'Genus' in pattern or 'Generated on' in pattern:
                        metadata = self._metadata.get('netlist_success', {})
                    elif 'Quantus' in pattern or 'DATE' in pattern or 'VERSION' in pattern:
                        metadata = self._metadata.get('spef_step_end', {})
                    else:
                        metadata = {}
                    
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', ''),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
                else:
                    missing_items[pattern] = {}
            
            extra_items = {}
            if spef_info.get('status') == 'Skipped':
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
                extra_items["SPEF Reading was skipped"] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'reason': skip_reason
                }
            
            for error in errors:
                if "SPEF reading was skipped" not in error:
                    extra_items[f"Error: {error}"] = {
                        'reason': 'Unexpected error'
                    }
            
            return found_items, missing_items, extra_items
        
        name_extractor = self._build_name_extractor()
        return self.execute_value_check(
            parse_data,
            has_waiver=True,  # Type 3: waiver enabled
            default_file='N/A',
            name_extractor=name_extractor,
            found_reason="Version pattern matched",
            missing_reason="Required pattern not found",
            waived_base_reason="Version pattern not found",
            unused_waiver_reason="Waiver defined but no violation matched",
            extra_reason="Design has no spef/netlist file or unexpected error",
            found_desc="Netlist/SPEF version is correct",
            missing_desc="Netlist/SPEF version isn't correct",
            waived_desc="Waived version mismatches",
            extra_desc="Design has no spef/netlist file"
        )
    
    def _execute_type4(self, netlist_info: Dict[str, Any], spef_info: Dict[str, Any], 
                       errors: List[str]) -> CheckResult:
        """
        Type 4: Boolean check with waiver (LLM只需生成parse_data逻辑)
        """
        def parse_data():
            """LLM生成的业务逻辑：与Type1相同，Framework自动处理waiver"""
            found_items = {}
            missing_items = {}
            extra_items = {}
            
            netlist_status = netlist_info.get('status', 'Not Found')
            if netlist_status == 'Success':
                netlist_path = netlist_info.get('path', 'Unknown')
                version_str = netlist_info.get('version', 'Unknown')
                date_str = netlist_info.get('full_timestamp', netlist_info.get('date', 'Unknown'))
                
                metadata = self._metadata.get('netlist_success', {})
                found_items['Netlist File'] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': netlist_path
                }
            else:
                missing_items['Netlist File'] = {
                    'note': f'Netlist status: {netlist_status}'
                }
            
            spef_status = spef_info.get('status', 'Not Found')
            if spef_status == 'Success':
                spef_path = spef_info.get('path', 'Unknown')
                version_str = spef_info.get('version', 'Unknown')
                date_str = spef_info.get('date', 'Unknown')
                
                metadata = self._metadata.get('spef_step_end', {})
                found_items['SPEF File'] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': spef_path
                }
            elif spef_status == 'Skipped':
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
                extra_items["SPEF Reading was skipped"] = {
                    'line_number': metadata.get('line_number', ''),
                    'file_path': metadata.get('file_path', ''),
                    'reason': skip_reason
                }
            else:
                missing_items['SPEF File'] = {
                    'note': f'SPEF status: {spef_status}'
                }
            
            for error in errors:
                if "SPEF reading was skipped" not in error:
                    extra_items[f"Error: {error}"] = {
                        'reason': 'Unexpected error'
                    }
            
            return found_items, missing_items, extra_items
        
        name_extractor = self._build_name_extractor()
        return self.execute_boolean_check(
            parse_data,
            has_waiver=True,  # Type 4: waiver enabled
            default_file='N/A',
            name_extractor=name_extractor,
            found_reason="File successfully loaded",
            missing_reason="File not loaded",
            waived_base_reason="File not loaded",
            unused_waiver_reason="Waiver defined but no violation matched",
            extra_reason="Design has no spef/netlist file or unexpected error",
            found_desc="Netlist/SPEF files are loaded",
            missing_desc="Netlist/SPEF files are not loaded",
            waived_desc="Waived file loading issues",
            extra_desc="Design has no spef/netlist file"
        )
    
    def _build_name_extractor(self):
        """Build name extractor for formatting output names."""
        def extract_name(name, metadata):
            if isinstance(metadata, dict):
                version = metadata.get('version', '')
                date = metadata.get('date', '')
                note = metadata.get('note', '')
                matched = metadata.get('matched', '')
                reason = metadata.get('reason', '')
                
                if version and date:
                    return f"{name}, Version: {version}, Date: {date}"
                elif note:
                    return f"{name} ({note})"
                elif matched:
                    return f"{name}: {matched}"
                elif reason:
                    return f"{name}: {reason}"
            return name
        
        return extract_name
    
    def execute_check(self) -> CheckResult:
        """Execute the check and return result."""
        try:
            # Parse input files
            netlist_info, spef_info, errors = self._parse_input_files()
            
            self._netlist_info = netlist_info
            self._spef_info = spef_info
            
            # Auto-detect check type
            check_type = self.detect_checker_type()
            
            # Execute appropriate type method
            if check_type == 1:
                return self._execute_type1(netlist_info, spef_info, errors)
            elif check_type == 2:
                return self._execute_type2(netlist_info, spef_info, errors)
            elif check_type == 3:
                return self._execute_type3(netlist_info, spef_info, errors)
            elif check_type == 4:
                return self._execute_type4(netlist_info, spef_info, errors)
            else:
                raise ConfigurationError(f"Invalid check type detected: {check_type}")
        
        except ConfigurationError as e:
            return create_check_result(
                value="N/A",
                is_pass=False,
                details=[
                    DetailItem(
                        severity=Severity.FAIL,
                        name=f"Configuration Error: {str(e)}",
                        line_number=0,
                        file_path="N/A",
                        reason="Invalid configuration"
                    )
                ]
            )
        except Exception as e:
            return create_check_result(
                value="N/A",
                is_pass=False,
                details=[
                    DetailItem(
                        severity=Severity.FAIL,
                        name=f"Unexpected Error: {str(e)}",
                        line_number=0,
                        file_path="N/A",
                        reason="Execution failed"
                    )
                ]
            )


def main():
    """Entry point for standalone execution."""
    checker = NetlistSpefVersionChecker()
    result = checker.execute_check()
    print(result)


if __name__ == "__main__":
    main()
