# -*- coding: utf-8 -*-
"""
NetlistSpefVersionChecker.py - Checker Implementation for IMP-10-0-0-00

Description:
    Confirm the netlist/spef version is correct.

Author: CodeGen Agent
Created: 2025-12-30
Version: v1.0.0

This file was auto-generated by CodeGen Agent.
Manual modifications may be overwritten on regeneration.
"""


from pathlib import Path
import gzip
import re
import sys
from typing import List, Dict, Tuple, Optional, Any


# Add common module to path
_SCRIPT_DIR = Path(__file__).resolve().parent
_CHECK_MODULES_DIR = _SCRIPT_DIR.parents[2]  # Go up to Check_modules/
_COMMON_DIR = _CHECK_MODULES_DIR / 'common'
if str(_COMMON_DIR) not in sys.path:
    sys.path.insert(0, str(_COMMON_DIR))

# Framework imports
from base_checker import BaseChecker, CheckResult, ConfigurationError
from output_formatter import DetailItem, Severity, create_check_result
from checker_templates.waiver_handler_template import WaiverHandlerMixin
from checker_templates.output_builder_template import OutputBuilderMixin

from checker_templates.input_file_parser_template import InputFileParserMixin


# MANDATORY: Inherit mixins in correct order (InputFileParserMixin first if used)
class NetlistSpefVersionChecker(InputFileParserMixin, OutputBuilderMixin, WaiverHandlerMixin, BaseChecker):
    """
    IMP-10-0-0-00: Confirm the netlist/spef version is correct.
    
    Checking Types:
    - Type 1: requirements=N/A, pattern_items [], waivers=N/A/0 → Boolean Check
    - Type 2: requirements>0, pattern_items [...], waivers=N/A/0 → Value Check
    - Type 3: requirements>0, pattern_items [...], waivers>0 → Value Check with Waiver Logic
    - Type 4: requirements=N/A, pattern_items [], waivers>0 → Boolean Check with Waiver Logic
    
    Template Library v1.1.0:
    - Uses InputFileParserMixin for parsing (parse_log_with_patterns, normalize_command)
    - Uses WaiverHandlerMixin for waiver processing (parse_waive_items, match_waiver_entry)
    - Uses OutputBuilderMixin for result construction (build_complete_output)
    """
    
    # =========================================================================
    # UNIFIED DESCRIPTIONS - Class-level constants (LLM-Generated)
    # =========================================================================
    FOUND_DESC = "Netlist/SPEF files loaded successfully"
    MISSING_DESC = "Netlist/SPEF loading issues"
    WAIVED_DESC = "Version check waived for current flow stage"
    FOUND_REASON = "Status: Success"
    MISSING_REASON = "File loading failed"
    WAIVED_BASE_REASON = "Version check waived"
    EXTRA_REASON = "Design has no spef/netlist file or unexpected error"
    UNUSED_WAIVER_REASON = "Waiver defined but not applied (version metadata found)"
    
    def __init__(self):
        """Initialize the checker."""
        super().__init__(
            check_module="UNKNOWN",
            item_id="IMP-10-0-0-00",
            item_desc="Confirm the netlist/spef version is correct."
        )
        # MANDATORY: Metadata tracking for debug (Golden pattern)
        # Used by helper methods to track line numbers for DetailItem
        self._metadata: Dict[str, Dict[str, Any]] = {}
        # Store parsed data
        self._parsed_items: List[Dict] = []
    
    # =========================================================================
    # Main Check Execution (Template - Fixed, v2.1 Golden-Aligned)
    # =========================================================================
    
    def execute_check(self) -> CheckResult:
        """
        Execute check with automatic type detection and delegation.
        
        v2.1: Aligned with Golden design pattern:
        1. Parse input files first via _parse_input_files()
        2. Pass parsed data to _execute_typeN(parsed_data)
        
        Returns:
            CheckResult based on detected checker type
        """
        try:
            if self.root is None:
                raise RuntimeError("Checker not initialized. Call init_checker() first.")
            
            # Parse input files first (Golden pattern)
            parsed_data = self._parse_input_files()
            
            # Detect checker type (use BaseChecker method)
            checker_type = self.detect_checker_type()
            
            # Execute based on type, passing parsed data
            if checker_type == 1:
                return self._execute_type1(parsed_data)
            elif checker_type == 2:
                return self._execute_type2(parsed_data)
            elif checker_type == 3:
                return self._execute_type3(parsed_data)
            else:  # checker_type == 4
                return self._execute_type4(parsed_data)
        except ConfigurationError as e:
            return e.check_result
    
    # =========================================================================
    # Input Parsing (LLM-Generated)
    # =========================================================================
    
    def _parse_input_files(self) -> Dict[str, Any]:
        """
        Parse input files to extract netlist and SPEF version information.
        
        Returns:
            Dict with keys:
            - netlist_info: Dict with netlist metadata
            - spef_info: Dict with SPEF metadata
            - errors: List of error messages
        """
        # Initialize metadata storage
        self._metadata = {}
        
        # Parse STA log first
        sta_info = self._parse_sta_log()
        
        netlist_info = {}
        spef_info = {}
        errors = list(sta_info.get('errors', []))
        
        # Parse netlist file if found
        if sta_info.get('netlist_path'):
            netlist_path = sta_info['netlist_path']
            netlist_info = self._parse_netlist_version(netlist_path)
            netlist_info['path'] = str(netlist_path)
            netlist_info['status'] = sta_info.get('netlist_status', 'Unknown')
            
            if not netlist_info.get('version'):
                errors.append(f"Failed to extract version from netlist: {netlist_path.name}")
        elif sta_info.get('netlist_relative_path'):
            # Netlist path found but file doesn't exist
            netlist_info['relative_path'] = sta_info['netlist_relative_path']
            netlist_info['status'] = sta_info.get('netlist_status', 'Unknown')
            netlist_info['note'] = 'File path found in log but actual file not accessible'
        else:
            errors.append("Netlist file path not found in STA log")
        
        # Parse SPEF file if found
        if sta_info.get('spef_path'):
            spef_path = sta_info['spef_path']
            spef_info = self._parse_spef_version(spef_path)
            spef_info['path'] = str(spef_path)
            spef_info['status'] = sta_info.get('spef_status', 'Unknown')
            
            if not spef_info.get('version'):
                errors.append(f"Failed to extract version from SPEF: {spef_path.name}")
        else:
            # SPEF might be intentionally skipped or not found
            spef_status = sta_info.get('spef_status', 'Not Found')
            spef_info['status'] = spef_status
            if spef_status == 'Skipped':
                # Get skip reason from metadata
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = metadata.get('reason', 'SPEF reading was skipped')
                # Remove [INFO] prefix if present
                skip_reason = skip_reason.replace('[INFO] ', '')
                spef_info['skip_reason'] = skip_reason
            elif spef_status == 'Not Found':
                if 'spef_step_end' not in self._metadata:
                    errors.append("SPEF file path not found in STA log")
        
        return {
            'netlist_info': netlist_info,
            'spef_info': spef_info,
            'errors': errors
        }
    
    # =========================================================================
    # Type 1: Boolean Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 1: Boolean check with automatic waiver.value=0 support
        
        Check if netlist and SPEF are loaded successfully.
        "Skipping SPEF reading" counts as FAIL.
        
        Waiver Logic (Automatic via build_complete_output):
        - waiver.value = 0: Auto-convert FAIL→INFO, force PASS [WAIVED_AS_INFO]
        - waiver.value = N/A: Normal mode
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        found_items = {}
        missing_items = []
        
        # Check netlist
        netlist_status = netlist_info.get('status', 'Not Found')
        if netlist_status == 'Success':
            if netlist_info.get('path'):
                netlist_path = netlist_info.get('path', 'Unknown')
                version_str = netlist_info.get('version', 'Unknown')
                date_str = netlist_info.get('full_timestamp', netlist_info.get('date', 'Unknown'))
                
                metadata = self._metadata.get('netlist_success', {})
                item_name = f"Netlist: {netlist_path}"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str
                }
            elif netlist_info.get('relative_path'):
                netlist_rel_path = netlist_info['relative_path']
                metadata = self._metadata.get('netlist_success', {})
                item_name = f"Netlist: {netlist_rel_path}"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'note': 'found in log, file not accessible'
                }
        else:
            missing_items.append(f"Netlist (Status: {netlist_status})")
        
        # Check SPEF
        spef_status = spef_info.get('status', 'Not Found')
        if spef_status == 'Success':
            if spef_info.get('path'):
                spef_path = spef_info.get('path', 'Unknown')
                version_str = spef_info.get('version', 'Unknown')
                date_str = spef_info.get('date', 'Unknown')
                
                metadata = self._metadata.get('spef_step_end', {})
                item_name = f"SPEF: {spef_path}"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str
                }
        elif spef_status == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = metadata.get('reason', 'SPEF reading was skipped')
            skip_reason = skip_reason.replace('[INFO] ', '')
            missing_items.append(f"SPEF Reading was skipped ({skip_reason})")
        else:
            missing_items.append(f"SPEF (Status: {spef_status})")
        
        # Add other errors
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                missing_items.append(f"Error: {error}")
        
        return self.build_complete_output(
            found_items=found_items,
            missing_items=missing_items,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 2: Value Check (LLM-Generated)
    # =========================================================================
    
    def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 2: Value comparison with automatic waiver.value=0 support
        
        Match required items in pattern_items against netlist/SPEF content.
        Expected value = number of items that should be found (should match pattern_items count).
        
        Waiver Logic (Automatic via build_complete_output):
        - waiver.value = 0: Auto-convert FAIL/WARN→INFO, force PASS [WAIVED_AS_INFO]
        - waiver.value = N/A: Normal mode
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        requirements = self.item_data.get('requirements', {})
        pattern_items = requirements.get('pattern_items', []) if requirements else []
        
        found_items = {}
        missing_items = []
        extra_items = {}  # Items not in pattern (SPEF issues, etc.)
        
        # Collect all content to search
        all_content = []
        
        # Add netlist version info
        if netlist_info.get('tool'):
            all_content.append(f"Tool: {netlist_info['tool']}")
        if netlist_info.get('version'):
            all_content.append(f"Genus Synthesis Solution {netlist_info['version']}")
        if netlist_info.get('full_timestamp'):
            all_content.append(f"Generated on: {netlist_info['full_timestamp']}")
        
        # Add SPEF version info
        if spef_info.get('program'):
            all_content.append(f"Program: {spef_info['program']}")
        if spef_info.get('version'):
            all_content.append(f"VERSION {spef_info['version']}")
        if spef_info.get('date'):
            all_content.append(f"DATE {spef_info['date']}")
        
        # Match patterns against content
        matched_patterns = set()
        for pattern in pattern_items:
            found = False
            matched_content = None
            for content in all_content:
                if self._match_pattern(content, [pattern]):
                    found = True
                    matched_content = content
                    break
            
            if found:
                matched_patterns.add(pattern)
                # Build found_items with file/version metadata
                if netlist_info.get('path') and ('Genus' in pattern or 'Generated on' in pattern):
                    metadata = self._metadata.get('netlist_success', {})
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', 0),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
                elif spef_info.get('path') and ('Quantus' in pattern or 'DATE' in pattern or 'VERSION' in pattern):
                    metadata = self._metadata.get('spef_step_end', {})
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', 0),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
                else:
                    found_items[pattern] = {
                        'line_number': 0,
                        'file_path': '',
                        'matched': matched_content
                    }
        
        # Find unmatched patterns
        missing_items = [p for p in pattern_items if p not in matched_patterns]
        
        # Check SPEF skip status - add as extra_item if skipped
        if spef_info.get('status') == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            extra_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        
        # Add other errors as extra items
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                extra_items[f"Error: {error}"] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': 'Unexpected error'
                }
        
        return self.build_complete_output(
            found_items=found_items,
            missing_items=missing_items,
            extra_items=extra_items,
            found_desc="Netlist/SPEF version is correct",
            missing_desc="Netlist/SPEF version isn't correct",
            extra_desc="Design has no spef/netlist file",
            name_extractor=self._build_name_extractor()
        )
    
    # =========================================================================
    # Type 3: Value Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 3: Value check with waiver logic
        
        Match pattern_items and apply waiver logic for missing items.
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        # Get configuration
        requirements = self.item_data.get('requirements', {})
        pattern_items = requirements.get('pattern_items', []) if requirements else []
        waive_items_dict = self.get_waive_items_with_reasons()
        
        # Collect all content to search
        all_content = []
        if netlist_info.get('tool'):
            all_content.append(f"Tool: {netlist_info['tool']}")
        if netlist_info.get('version'):
            all_content.append(f"Genus Synthesis Solution {netlist_info['version']}")
        if netlist_info.get('full_timestamp'):
            all_content.append(f"Generated on: {netlist_info['full_timestamp']}")
        if spef_info.get('program'):
            all_content.append(f"Program: {spef_info['program']}")
        if spef_info.get('version'):
            all_content.append(f"VERSION {spef_info['version']}")
        if spef_info.get('date'):
            all_content.append(f"DATE {spef_info['date']}")
        
        # Classify: found / missing / waived
        matched_patterns = set()
        waived_patterns = []
        used_waivers = set()
        
        for pattern in pattern_items:
            found = False
            for content in all_content:
                if self._match_pattern(content, [pattern]):
                    found = True
                    matched_patterns.add(pattern)
                    break
            
            if not found:
                # Check if waived using word-level matching
                is_waived, waiver_key, waiver_reason = self.is_item_waived_word_level(pattern, waive_items_dict)
                if is_waived:
                    waived_patterns.append(pattern)
                    used_waivers.add(waiver_key)
        
        missing_patterns = [p for p in pattern_items 
                            if p not in matched_patterns and p not in waived_patterns]
        unused_waivers = [w for w in waive_items_dict if w not in used_waivers]
        
        # Build details
        details = []
        
        for pattern in matched_patterns:
            # Find matched content
            matched_content = None
            for content in all_content:
                if self._match_pattern(content, [pattern]):
                    matched_content = content
                    break
            
            # Determine metadata source
            if netlist_info.get('path') and ('Genus' in pattern or 'Generated on' in pattern):
                metadata = self._metadata.get('netlist_success', {})
            elif spef_info.get('path') and ('Quantus' in pattern or 'DATE' in pattern or 'VERSION' in pattern):
                metadata = self._metadata.get('spef_step_end', {})
            else:
                metadata = {}
            
            details.append(DetailItem(
                severity=Severity.INFO,
                name=pattern,
                line_number=metadata.get('line_number', 0),
                file_path=metadata.get('file_path', ''),
                reason=f"Version pattern matched: {matched_content}"
            ))
        
        for pattern in waived_patterns:
            is_waived, waiver_key, waiver_reason = self.is_item_waived_word_level(pattern, waive_items_dict)
            reason = f"Required pattern not found[WAIVER]"
            if waiver_reason:
                reason = f"Required pattern not found: {waiver_reason}[WAIVER]"
            details.append(DetailItem(
                severity=Severity.INFO,
                name=pattern,
                line_number=0,
                file_path='',
                reason=reason
            ))
        
        for pattern in missing_patterns:
            details.append(DetailItem(
                severity=Severity.FAIL,
                name=pattern,
                line_number=0,
                file_path='',
                reason="Required pattern not found"
            ))
        
        for waiver_key in unused_waivers:
            details.append(DetailItem(
                severity=Severity.WARN,
                name=waiver_key,
                line_number=0,
                file_path='',
                reason="Waiver not used[WAIVER]"
            ))
        
        # Build groups
        error_groups = None
        info_groups = None
        warn_groups = None
        
        if missing_patterns:
            error_groups = {"ERROR01": {"description": "Netlist/SPEF version isn't correct", "items": missing_patterns}}
        if matched_patterns:
            info_groups = {"INFO01": {"description": "Netlist/SPEF version is correct", "items": list(matched_patterns)}}
        if unused_waivers:
            warn_groups = {"WARN01": {"description": "Unused waivers", "items": unused_waivers}}
        
        return create_check_result(
            value=len(matched_patterns),
            is_pass=len(missing_patterns) == 0,
            has_pattern_items=True,
            has_waiver_value=True,
            details=details,
            error_groups=error_groups,
            info_groups=info_groups,
            warn_groups=warn_groups,
            item_desc=self.item_desc
        )
    
    # =========================================================================
    # Type 4: Boolean Check with Waiver Logic (LLM-Generated)
    # =========================================================================
    
    def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 4: Boolean check with waiver logic
        
        Check if version metadata exists, with waiver support for flow stages.
        """
        netlist_info = parsed_data.get('netlist_info', {})
        spef_info = parsed_data.get('spef_info', {})
        errors = parsed_data.get('errors', [])
        
        waive_items_dict = self.get_waive_items_with_reasons()
        
        found_items = {}
        missing_items = []
        waived_items = []
        used_waivers = set()
        
        # Check netlist
        netlist_status = netlist_info.get('status', 'Not Found')
        if netlist_status == 'Success':
            if netlist_info.get('path'):
                netlist_path = netlist_info.get('path', 'Unknown')
                version_str = netlist_info.get('version', 'Unknown')
                date_str = netlist_info.get('full_timestamp', netlist_info.get('date', 'Unknown'))
                
                metadata = self._metadata.get('netlist_success', {})
                item_name = f"Netlist: {netlist_path}"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str
                }
        else:
            netlist_issue = f"Netlist (Status: {netlist_status})"
            is_waived, waiver_key, waiver_reason = self.is_item_waived_word_level(netlist_issue, waive_items_dict)
            if is_waived:
                waived_items.append(netlist_issue)
                used_waivers.add(waiver_key)
            else:
                missing_items.append(netlist_issue)
        
        # Check SPEF
        spef_status = spef_info.get('status', 'Not Found')
        if spef_status == 'Success':
            if spef_info.get('path'):
                spef_path = spef_info.get('path', 'Unknown')
                version_str = spef_info.get('version', 'Unknown')
                date_str = spef_info.get('date', 'Unknown')
                
                metadata = self._metadata.get('spef_step_end', {})
                item_name = f"SPEF: {spef_path}"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str
                }
        elif spef_status == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = metadata.get('reason', 'SPEF reading was skipped')
            skip_reason = skip_reason.replace('[INFO] ', '')
            spef_issue = f"SPEF Reading was skipped ({skip_reason})"
            
            # Check if SPEF skip is waived
            is_waived, waiver_key, waiver_reason = self.is_item_waived_word_level(spef_issue, waive_items_dict)
            if is_waived:
                waived_items.append(spef_issue)
                used_waivers.add(waiver_key)
            else:
                missing_items.append(spef_issue)
        else:
            spef_issue = f"SPEF (Status: {spef_status})"
            is_waived, waiver_key, waiver_reason = self.is_item_waived_word_level(spef_issue, waive_items_dict)
            if is_waived:
                waived_items.append(spef_issue)
                used_waivers.add(waiver_key)
            else:
                missing_items.append(spef_issue)
        
        unused_waivers = [w for w in waive_items_dict if w not in used_waivers]
        
        return self.build_complete_output(
            found_items=found_items,
            missing_items=missing_items,
            waived_items=waived_items,
            unused_waivers=unused_waivers,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            waived_desc=self.WAIVED_DESC,
            name_extractor=self._build_name_extractor()
        )

    # =========================================================================
    # Helper Methods (LLM-Generated)
    # =========================================================================
    
    def _build_name_extractor(self):
        """返回 name_extractor 函数，用于格式化输出"""
        def extract_name(name: str, metadata: Any) -> str:
            if isinstance(metadata, dict):
                version = metadata.get('version', '')
                date = metadata.get('date', '')
                note = metadata.get('note', '')
                matched = metadata.get('matched', '')
                reason = metadata.get('reason', '')
                
                if version and date:
                    return f"{name}, Version: {version}, Date: {date}"
                elif note:
                    return f"{name} ({note})"
                elif matched:
                    return f"{name}: {matched}"
                elif reason:
                    return f"{name}: {reason}"
            return name
        return extract_name

    def _parse_sta_log(self) -> Dict[str, Any]:
        """
        Parse STA log file to extract netlist/SPEF information.
        
        Returns:
            Dict with keys:
            - netlist_path: Path to netlist file
            - netlist_status: Success/Failed
            - spef_path: Path to SPEF file (if any)
            - spef_status: Success/Failed/Skipped
            - errors: List of error messages
        """
        sta_info = {
            'netlist_path': None,
            'netlist_status': 'Not Found',
            'spef_path': None,
            'spef_status': 'Not Found',
            'errors': [],
            'warnings': []
        }
        
        # Validate input_files configuration
        if not self.item_data or 'input_files' not in self.item_data:
            sta_info['errors'].append("No input_files specified in configuration")
            return sta_info
        
        input_files = self.item_data['input_files']
        
        if isinstance(input_files, str):
            input_files = [input_files]
        
        if not input_files:
            sta_info['errors'].append("input_files list is empty")
            return sta_info
        
        for file_path_str in input_files:
            file_path = Path(file_path_str)
            
            if not file_path.exists():
                sta_info['errors'].append(f"STA log file not found: {file_path_str}")
                continue
            
            sta_log_dir = file_path.parent
            
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
            except Exception as e:
                sta_info['errors'].append(f"Failed to read STA log: {e}")
                continue
            
            for line_num, line in enumerate(lines, 1):
                # Extract netlist file path
                if 'read_netlist' in line and '<CMD>' in line:
                    match = re.search(r'read_netlist\s+(\S+)', line)
                    if match:
                        netlist_rel_path = match.group(1)
                        netlist_abs_path = self._resolve_relative_path(netlist_rel_path, sta_log_dir)
                        if netlist_abs_path:
                            sta_info['netlist_path'] = netlist_abs_path
                        else:
                            sta_info['netlist_relative_path'] = netlist_rel_path
                        
                        self._metadata['netlist_cmd'] = {
                            'line_number': line_num,
                            'file_path': str(file_path),
                            'relative_path': netlist_rel_path
                        }
                
                # Reading verilog netlist
                elif 'Reading verilog netlist' in line:
                    match = re.search(r"Reading verilog netlist\s+'([^']+)'", line)
                    if match:
                        netlist_rel_path = match.group(1)
                        if not sta_info.get('netlist_path'):
                            netlist_abs_path = self._resolve_relative_path(netlist_rel_path, sta_log_dir)
                            if netlist_abs_path:
                                sta_info['netlist_path'] = netlist_abs_path
                            else:
                                sta_info['netlist_relative_path'] = netlist_rel_path
                    
                    self._metadata['netlist_reading'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                # Check netlist success
                elif '*** Netlist is unique' in line or 'Netlist is unique' in line:
                    sta_info['netlist_status'] = 'Success'
                    self._metadata['netlist_success'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                # Check for SPEF reading
                elif 'Skipping SPEF reading' in line:
                    sta_info['spef_status'] = 'Skipped'
                    sta_info['errors'].append("SPEF reading was skipped")
                    self._metadata['spef_skipped'] = {
                        'line_number': line_num,
                        'file_path': str(file_path),
                        'reason': line.strip()
                    }
                
                # read_parasitics step
                elif 'Begin flow_step read_parasitics' in line:
                    self._metadata['spef_step_begin'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                elif 'End flow_step read_parasitics' in line:
                    self._metadata['spef_step_end'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                    if sta_info['spef_status'] != 'Skipped':
                        sta_info['spef_status'] = 'Success'
                
                # Look for SPEF file path
                elif 'read_spef' in line.lower() or 'read_parasitics' in line.lower():
                    match = re.search(r'([\w/\.\-]+\.spef(?:\.gz)?)', line, re.IGNORECASE)
                    if match:
                        spef_rel_path = match.group(1)
                        spef_abs_path = self._resolve_relative_path(spef_rel_path, sta_log_dir)
                        if spef_abs_path:
                            sta_info['spef_path'] = spef_abs_path
                
                # Check for errors
                elif re.search(r'\b(error|failed)\b', line, re.IGNORECASE):
                    if 'netlist' in line.lower() or 'spef' in line.lower():
                        sta_info['errors'].append(f"Line {line_num}: {line.strip()}")
        
        # Final status determination
        if sta_info.get('netlist_relative_path') or sta_info.get('netlist_path'):
            if 'netlist_success' in self._metadata:
                sta_info['netlist_status'] = 'Success'
            elif sta_info['netlist_status'] == 'Not Found':
                sta_info['netlist_status'] = 'Read Command Found'
        
        return sta_info

    def _parse_netlist_version(self, netlist_path: Path) -> Dict[str, str]:
        """
        Parse netlist file to extract version information.
        
        Expected format:
        // Generated by Cadence Genus(TM) Synthesis Solution 23.15-s099_1
        // Generated on: Nov 18 2025 15:58:15 IST (Nov 18 2025 10:28:15 UTC)
        
        Returns:
            Dict with keys: tool, version, date, time
        """
        version_info = {
            'tool': '',
            'version': '',
            'date': '',
            'time': '',
            'full_timestamp': ''
        }
        
        if not netlist_path.exists():
            return version_info
        
        lines = self._read_file_content(netlist_path, max_lines=50)
        
        for line in lines:
            # Extract tool and version
            if 'Generated by' in line and 'Genus' in line:
                match = re.search(r'Synthesis Solution\s+([\d\.\-\w]+)', line)
                if match:
                    version_info['tool'] = 'Cadence Genus Synthesis Solution'
                    version_info['version'] = match.group(1)
            
            # Extract generation date
            elif 'Generated on:' in line:
                match = re.search(r'Generated on:\s+(\w+\s+\d+\s+\d+)\s+([\d:]+)', line)
                if match:
                    version_info['date'] = match.group(1)
                    version_info['time'] = match.group(2)
                    version_info['full_timestamp'] = f"{match.group(1)} {match.group(2)}"
        
        return version_info

    def _parse_spef_version(self, spef_path: Path) -> Dict[str, str]:
        """
        Parse SPEF file to extract version information.
        
        Expected format:
        *SPEF "IEEE 1481-1999"
        *DESIGN "design_name"
        *DATE "Tue Jun 10 14:16:48 2025"
        *VENDOR "Cadence Design Systems Inc"
        *PROGRAM "Cadence Quantus Extraction"
        *VERSION "23.1.0-p075 Tue Sep 26 09:27:40 PDT 2023"
        
        Returns:
            Dict with keys: design, date, vendor, program, version
        """
        version_info = {
            'design': '',
            'date': '',
            'vendor': '',
            'program': '',
            'version': '',
            'spef_standard': ''
        }
        
        if not spef_path.exists():
            return version_info
        
        lines = self._read_file_content(spef_path, max_lines=100)
        
        for line in lines:
            if line.startswith('*SPEF'):
                match = re.search(r'\*SPEF\s+"([^"]+)"', line)
                if match:
                    version_info['spef_standard'] = match.group(1)
            
            elif line.startswith('*DESIGN'):
                match = re.search(r'\*DESIGN\s+"([^"]+)"', line)
                if match:
                    version_info['design'] = match.group(1)
            
            elif line.startswith('*DATE'):
                match = re.search(r'\*DATE\s+"([^"]+)"', line)
                if match:
                    version_info['date'] = match.group(1)
            
            elif line.startswith('*VENDOR'):
                match = re.search(r'\*VENDOR\s+"([^"]+)"', line)
                if match:
                    version_info['vendor'] = match.group(1)
            
            elif line.startswith('*PROGRAM'):
                match = re.search(r'\*PROGRAM\s+"([^"]+)"', line)
                if match:
                    version_info['program'] = match.group(1)
            
            elif line.startswith('*VERSION'):
                match = re.search(r'\*VERSION\s+"([^"]+)"', line)
                if match:
                    version_info['version'] = match.group(1)
        
        return version_info

    def _read_file_content(self, file_path: Path, max_lines: int = 100) -> List[str]:
        """
        Read file content, supporting both plain text and gzip compressed files.
        
        Args:
            file_path: Path to the file
            max_lines: Maximum number of lines to read from start
            
        Returns:
            List of lines from the file
        """
        if not file_path.exists():
            return []
        
        try:
            # Check if file is gzipped
            if file_path.suffix == '.gz':
                try:
                    with gzip.open(file_path, 'rt', encoding='utf-8', errors='ignore') as f:
                        lines = []
                        for i, line in enumerate(f):
                            if i >= max_lines:
                                break
                            lines.append(line)
                        return lines
                except (gzip.BadGzipFile, OSError):
                    # Not a real gzip file, fall through to read as plain text
                    pass
            
            # Read as plain text file
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = []
                for i, line in enumerate(f):
                    if i >= max_lines:
                        break
                    lines.append(line)
                return lines
        except Exception as e:
            print(f"Warning: Failed to read {file_path}: {e}")
            return []

    def _resolve_relative_path(self, relative_path: str, sta_log_dir: Path) -> Optional[Path]:
        """
        Resolve relative path from STA log to absolute path.
        
        Args:
            relative_path: Relative path from STA log
            sta_log_dir: Directory containing the STA log file
            
        Returns:
            Absolute path if exists, None otherwise
        """
        if not relative_path:
            return None
        
        try:
            # Clean path
            clean_path = relative_path.strip().strip('"').strip("'")
            
            # Resolve relative to STA log directory
            abs_path = (sta_log_dir / clean_path).resolve()
            
            if abs_path.exists():
                return abs_path
            
            # If not found, try from project root
            if hasattr(self, 'root') and self.root:
                abs_path = (self.root / clean_path).resolve()
                if abs_path.exists():
                    return abs_path
        except Exception as e:
            print(f"Warning: Failed to resolve path {relative_path}: {e}")
        
        return None

    def _match_pattern(self, text: str, patterns: List[str]) -> Optional[str]:
        """
        Check if text matches any pattern.
        
        Args:
            text: Text to check
            patterns: List of patterns (supports wildcards)
            
        Returns:
            Matched pattern if found, None otherwise
        """
        for pattern in patterns:
            try:
                # Convert wildcard to regex
                regex_pattern = pattern
                if '*' in pattern and not pattern.startswith('^'):
                    regex_pattern = pattern.replace('*', '.*')
                
                if re.search(regex_pattern, text, re.IGNORECASE):
                    return pattern
            except re.error:
                # Regex error, try exact match
                if pattern.lower() in text.lower():
                    return pattern
        return None


# ============================================================================
# Entry Point (Template - Fixed, Golden-Aligned)
# ============================================================================

def init_checker() -> NetlistSpefVersionChecker:
    """Initialize and return the checker instance."""
    checker = NetlistSpefVersionChecker()
    checker.init_checker()
    return checker


if __name__ == '__main__':
    checker = init_checker()
    checker.execute_check()
    checker.write_output()
