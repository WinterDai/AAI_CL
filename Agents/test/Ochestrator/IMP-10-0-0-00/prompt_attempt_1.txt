# ğŸ“š å­¦ä¹ ææ–™ (Grounding Data)

## ğŸŒŸ Golden ä»£ç ç‰‡æ®µ (è¡¥å……å‚è€ƒ)

ä»¥ä¸‹æ˜¯æ¥è‡ª Golden ä»£ç çš„å…³é”®æ–¹æ³•å®ç°ï¼š

**_parse_input_files**:
```python
def _parse_input_files(self) -> Dict[str, Any]:
        """
        Parse input files to extract netlist and SPEF version information.
        
        Returns:
            Dict with keys:
            - netlist_info: Dict with netlist metadata
            - spef_info: Dict with SPEF metadata
            - errors: List of error messages
        """
        # Initialize metadata storage
        self._metadata = {}
        
        # Parse STA log first
        sta_log_info = self._parse_sta_log()
        
        netlist_info = {}
        spef_info = {}
        errors = list(sta_log_info.get('errors', []))
        
        # Parse netlist file if found
        if sta_log_info.get('netlist_path'):
            netlist_path = sta_log_info['netlist_path']
            netlist_info = self._parse_netlist_version(netlist_path)
            netlist_info['path'] = str(netlist_path)
            netlist_info['status'] = sta_log_info.get('netlist_status', 'Unknown')
            
            if not netlist_info.get('version'):
                errors.append(f"Failed to extract version from netlist: {netlist_path.name}")
        elif sta_log_info.get('netlist_relative_path'):
            # Netlist path found but file doesn't exist
            netlist_info['relative_path'] = sta_log_info['netlist_relative_path']
            netlist_info['status'] = sta_log_info.get('netlist_status', 'Unknown')
            netlist_info['note'] = 'File path found in log but actual file not accessible'
        else:
            errors.append("Netlist file path not found in STA log")
        
        # Parse SPEF file if found
        if sta_log_info.get('spef_path'):
            spef_path = sta_log_info['spef_path']
            spef_info = self._parse_spef_version(spef_path)
            spef_info['path'] = str(spef_path)
            spef_info['status'] = sta_log_info.get('spef_status', 'Unknown')
            
            if not spef_info.get('version'):
                errors.append(f"Failed to extract version from SPEF: {spef_path.name}")
        else:
            # SPEF might be intentionally skipped or not found
            spef_status = sta_log_info.get('spef_status', 'Not Found')
            spef_info['status'] = spef_status
            if spef_status == 'Skipped':
                # Get skip reason from metadata
                metadata = self._metadata.get('spef_skipped', {})
                skip_reason = metadata.get('reason', 'SPEF reading was skipped')
                skip_reason = skip_reason.replace('[INFO] ', '').replace('INFO: ', '')
                spef_info['skip_reason'] = skip_reason
            elif spef_status == 'Not Found':
                if 'spef_step_end' not in self._metadata:
                    errors.append("SPEF file path not found in STA log")
        
        return {
            'netlist_info': netlist_info,
            'spef_info': spef_info,
            'errors': errors
        }
    
    # =========================================================================
    # Helper: Extract Data (è¾…åŠ©å‡½æ•°ï¼Œæ‰€æœ‰Typeå…±ç”¨)
    # =========================================================================
```

**_execute_type1**:
```python
def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 1: Boolean check - verify netlist and SPEF are loaded successfully
        
        æ¶æ„ï¼šBoolean Logic + æ— Waiver
        Pass Condition: Both files read with Status: Success
        Fail Condition: Any file read failed
        """
        def parse_data():
            """è°ƒç”¨å…±äº«çš„Boolean Check Logic"""
            return self._boolean_check_logic(parsed_data)
        
        return self.execute_boolean_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc=self.FOUND_DESC,
            missing_desc=self.MISSING_DESC,
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
```

**_execute_type2**:
```python
def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
        """
        Type 2: Value check - match version info from pattern_items
        
        æ¶æ„ï¼šPattern Logic + æ— Waiver
        Pass Condition: Pattern items found in output
        Fail Condition: Pattern items not found
        """
        def parse_data():
            """è°ƒç”¨å…±äº«çš„Pattern Check Logic"""
            return self._pattern_check_logic(parsed_data)        
        return self.execute_value_check(
            parse_data_func=parse_data,
            has_waiver=False,
            found_desc="Netlist/SPEF version is correct",
            missing_desc="Netlist/SPEF version isn't correct",
            extra_desc=self.EXTRA_DESC,
            name_extractor=self._build_name_extractor()
        )
```

**_extract_data**:
```python
def _extract_data(self, parsed_data: Dict[str, Any]) -> tuple:
        """Extract common data from parsed_data for all Types"""
        return (
            parsed_data.get('netlist_info', {}),
            parsed_data.get('spef_info', {}),
            parsed_data.get('errors', [])
        )
    
    # =========================================================================
    # Logic Check Modules (LLM-Generated, Layer 2: æ ¸å¿ƒé€»è¾‘æ¨¡å—)
    # =========================================================================
```

**_boolean_check_logic**:
```python
def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Boolean Check Logic (Type1/4å…±äº«)
        
        æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (å­˜åœ¨æ€§åˆ¤æ–­)
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        netlist_info, spef_info, errors = self._extract_data(parsed_data)
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Check netlist
        netlist_status = netlist_info.get('status', 'Not Found')
        if netlist_status == 'Success':
            if netlist_info.get('path'):
                netlist_path = netlist_info.get('path', 'Unknown')
                version_str = netlist_info.get('version', 'Unknown')
                date_str = netlist_info.get('full_timestamp', netlist_info.get('date', 'Unknown'))
                
                metadata = self._metadata.get('netlist_success', {})
                item_name = f"Netlist File"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': netlist_path
                }
            elif netlist_info.get('relative_path'):
                netlist_rel_path = netlist_info['relative_path']
                metadata = self._metadata.get('netlist_success', {})
                item_name = f"Netlist File"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'note': 'found in log, file not accessible',
                    'path': netlist_rel_path
                }
        else:
            missing_items[f"Netlist File"] = {
                'reason': f"Status: {netlist_status}"
            }
        
        # Check SPEF
        spef_status = spef_info.get('status', 'Not Found')
        if spef_status == 'Success':
            if spef_info.get('path'):
                spef_path = spef_info.get('path', 'Unknown')
                version_str = spef_info.get('version', 'Unknown')
                date_str = spef_info.get('date', 'Unknown')
                
                metadata = self._metadata.get('spef_step_end', {})
                item_name = f"SPEF File"
                found_items[item_name] = {
                    'line_number': metadata.get('line_number', 0),
                    'file_path': metadata.get('file_path', ''),
                    'version': version_str,
                    'date': date_str,
                    'path': spef_path
                }
        elif spef_status == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            missing_items["SPEF Reading was skipped"] = {
                'line_number': 0,
                'file_path': 'N/A',
                'reason': skip_reason
            }
        else:
            missing_items[f"SPEF File"] = {
                'reason': f"Status: {spef_status}"
            }
        
        # Add other errors as extra items
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                extra_items[f"Error: {error}"] = {
                    'reason': 'Unexpected error'
                }
        
        return found_items, missing_items, extra_items
```

**_pattern_check_logic**:
```python
def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
        """
        Pattern Check Logic (Type2/3å…±äº«)
        
        æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼šåŒ¹é…ç‰ˆæœ¬ä¿¡æ¯pattern (æ­£åˆ™åŒ¹é…)
        
        Returns:
            tuple: (found_items, missing_items, extra_items)
        """
        netlist_info, spef_info, errors = self._extract_data(parsed_data)
        
        # Get pattern_items from requirements
        requirements = self.item_data.get('requirements', {})
        pattern_items = requirements.get('pattern_items', [])
        
        found_items = {}
        missing_items = {}
        extra_items = {}
        
        # Collect all content to search
        all_content = []
        
        # Add netlist version info
        if netlist_info.get('tool'):
            all_content.append(f"Tool: {netlist_info['tool']}")
        if netlist_info.get('version'):
            all_content.append(f"Genus Synthesis Solution {netlist_info['version']}")
        if netlist_info.get('full_timestamp'):
            all_content.append(f"Generated on: {netlist_info['full_timestamp']}")
        
        # Add SPEF version info
        if spef_info.get('program'):
            all_content.append(f"Program: {spef_info['program']}")
        if spef_info.get('version'):
            all_content.append(f"VERSION {spef_info['version']}")
        if spef_info.get('date'):
            all_content.append(f"DATE {spef_info['date']}")
        
        # Match patterns against content
        matched_patterns = set()
        for pattern in pattern_items:
            found = False
            matched_content = None
            for content in all_content:
                if self._match_pattern(content, [pattern]):
                    found = True
                    matched_content = content
                    break
            
            if found:
                matched_patterns.add(pattern)
                # Build found_items with file/version metadata
                if netlist_info.get('path') and ('Genus' in pattern or 'Generated on' in pattern):
                    metadata = self._metadata.get('netlist_success', {})
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', 0),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
                elif spef_info.get('path') and ('Quantus' in pattern or 'DATE' in pattern or 'VERSION' in pattern):
                    metadata = self._metadata.get('spef_step_end', {})
                    found_items[pattern] = {
                        'line_number': metadata.get('line_number', 0),
                        'file_path': metadata.get('file_path', ''),
                        'matched': matched_content
                    }
                else:
                    found_items[pattern] = {
                        'line_number': 0,
                        'file_path': '',
                        'matched': matched_content
                    }
        
        # Find unmatched patterns
        for p in pattern_items:
            if p not in matched_patterns:
                missing_items[p] = {
                    'reason': 'Required pattern not found'
                }
        
        # Check SPEF skip status - add as extra_item if skipped
        if spef_info.get('status') == 'Skipped':
            metadata = self._metadata.get('spef_skipped', {})
            skip_reason = spef_info.get('skip_reason', 'SPEF reading was skipped')
            extra_items["SPEF Reading was skipped"] = {
                'line_number': metadata.get('line_number', 0),
                'file_path': metadata.get('file_path', ''),
                'reason': skip_reason
            }
        
        # Add other errors as extra items
        for error in errors:
            if not any(e in error for e in ["SPEF reading was skipped"]):
                extra_items[f"Error"] = {
                    'line_number': 0,
                    'file_path': '',
                    'reason': error
                }
        
        return found_items, missing_items, extra_items
    
    # =========================================================================
    # Type Execution (Layer 3: Type1/2æ ¸å¿ƒæ‰§è¡Œï¼ŒType3/4å¤ç”¨Type1/2é€»è¾‘)
    # =========================================================================
```

**_parse_sta_log**:
```python
def _parse_sta_log(self) -> Dict[str, Any]:
        """
        Parse STA log file to extract netlist/SPEF information.
        
        Returns:
            Dict with keys:
            - netlist_path: Path to netlist file
            - netlist_status: Success/Failed
            - spef_path: Path to SPEF file (if any)
            - spef_status: Success/Failed/Skipped
            - errors: List of error messages
        """
        sta_info = {
            'netlist_path': None,
            'netlist_status': 'Not Found',
            'spef_path': None,
            'spef_status': 'Not Found',
            'errors': [],
            'warnings': []
        }
        
        # Validate input_files
        input_files_list, errors = self.validate_input_files()
        if errors:
            sta_info['errors'].extend(errors)
            return sta_info
        
        for file_path in input_files_list:
            if not file_path.exists():
                sta_info['errors'].append(f"STA log file not found: {file_path}")
                continue
            
            sta_log_dir = file_path.parent
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                # Extract netlist file path: "Read Netlist: /path/to/file.v.gz"
                if 'Read Netlist:' in line:
                    match = re.search(r'Read Netlist:\s*(.+)', line)
                    if match:
                        netlist_path_str = match.group(1).strip()
                        netlist_abs_path = self._resolve_relative_path(netlist_path_str, sta_log_dir)
                        if netlist_abs_path:
                            sta_info['netlist_path'] = netlist_abs_path
                        else:
                            sta_info['netlist_relative_path'] = netlist_path_str
                        
                        self._metadata['netlist_cmd'] = {
                            'line_number': line_num,
                            'file_path': str(file_path)
                        }
                
                # Alternative netlist detection: "Reading verilog netlist '/path/to/file.v.gz'"
                elif 'Reading verilog netlist' in line:
                    match = re.search(r"Reading verilog netlist\s+'([^']+)'", line)
                    if match:
                        netlist_rel_path = match.group(1)
                        if not sta_info.get('netlist_path'):
                            netlist_abs_path = self._resolve_relative_path(netlist_rel_path, sta_log_dir)
                            if netlist_abs_path:
                                sta_info['netlist_path'] = netlist_abs_path
                            else:
                                sta_info['netlist_relative_path'] = netlist_rel_path
                    
                    self._metadata['netlist_reading'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                # Netlist success indicator: "*** Netlist is unique"
                elif '*** Netlist is unique' in line or 'Netlist is unique' in line:
                    sta_info['netlist_status'] = 'Success'
                    self._metadata['netlist_success'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                # Check netlist status: "Status: Success"
                elif 'Status:' in line and sta_info.get('netlist_path'):
                    match = re.search(r'Status:\s*(Success|Failed)', line)
                    if match:
                        status = match.group(1)
                        if sta_info['netlist_status'] == 'Not Found' or 'netlist' in lines[max(0, line_num-5):line_num][-1].lower():
                            sta_info['netlist_status'] = status
                            if status == 'Success':
                                self._metadata['netlist_success'] = {
                                    'line_number': line_num,
                                    'file_path': str(file_path)
                                }
                
                # SPEF skip detection: "[INFO] Skipping SPEF reading"
                elif 'Skipping SPEF reading' in line:
                    sta_info['spef_status'] = 'Skipped'
                    sta_info['errors'].append("SPEF reading was skipped")
                    self._metadata['spef_skipped'] = {
                        'line_number': line_num,
                        'file_path': str(file_path),
                        'reason': line.strip()
                    }
                
                # Track SPEF reading flow step
                elif 'Begin flow_step read_parasitics' in line:
                    self._metadata['spef_step_begin'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                
                elif 'End flow_step read_parasitics' in line:
                    self._metadata['spef_step_end'] = {
                        'line_number': line_num,
                        'file_path': str(file_path)
                    }
                    if sta_info['spef_status'] != 'Skipped':
                        sta_info['spef_status'] = 'Success'
                
                # Extract SPEF file path: "Read SPEF: /path/to/file.spef.gz"
                elif 'Read SPEF:' in line:
                    match = re.search(r'Read SPEF:\s*(.+)', line)
                    if match:
                        spef_path_str = match.group(1).strip()
                        spef_abs_path = self._resolve_relative_path(spef_path_str, sta_log_dir)
                        if spef_abs_path:
                            sta_info['spef_path'] = spef_abs_path
                        
                        self._metadata['spef_cmd'] = {
                            'line_number': line_num,
                            'file_path': str(file_path)
                        }
                
                # Check SPEF status
                elif 'Status:' in line and sta_info.get('spef_path'):
                    match = re.search(r'Status:\s*(Success|Failed)', line)
                    if match:
                        status = match.group(1)
                        if sta_info['spef_status'] == 'Not Found' or 'spef' in lines[max(0, line_num-5):line_num][-1].lower():
                            sta_info['spef_status'] = status
                            if status == 'Success':
                                self._metadata['spef_step_end'] = {
                                    'line_number': line_num,
                                    'file_path': str(file_path)
                                }
        
        return sta_info
```

**_parse_netlist_version**:
```python
def _parse_netlist_version(self, netlist_path: Path) -> Dict[str, str]:
        """
        Parse netlist file to extract version information.
        
        Expected format:
        // Generated by Cadence Genus(TM) Synthesis Solution 23.15-s099_1
        // Generated on: Nov 18 2025 15:58:15 IST (Nov 18 2025 10:28:15 UTC)
        
        Returns:
            Dict with keys: tool, version, date, time, full_timestamp
        """
        version_info = {
            'tool': '',
            'version': '',
            'date': '',
            'time': '',
            'full_timestamp': ''
        }
        
        if not netlist_path.exists():
            return version_info
        
        lines = self._read_file_content(netlist_path, max_lines=50)
        
        for line in lines:
            # Extract tool and version
            if 'Generated by' in line and 'Genus' in line:
                match = re.search(r'Synthesis Solution\s+([\d\.\-\w]+)', line)
                if match:
                    version_info['tool'] = 'Cadence Genus Synthesis Solution'
                    version_info['version'] = match.group(1)
            
            # Extract generation date
            elif 'Generated on:' in line:
                match = re.search(r'Generated on:\s+(\w+\s+\d+\s+\d+)\s+([\d:]+)', line)
                if match:
                    version_info['date'] = match.group(1)
                    version_info['time'] = match.group(2)
                    version_info['full_timestamp'] = f"{match.group(1)} {match.group(2)}"
        
        return version_info
```

**_parse_spef_version**:
```python
def _parse_spef_version(self, spef_path: Path) -> Dict[str, str]:
        """
        Parse SPEF file to extract version information.
        
        Expected format:
        *SPEF "IEEE 1481-1999"
        *DATE "Tue Jun 10 14:16:48 2025"
        *PROGRAM "Cadence Quantus Extraction"
        *VERSION "23.1.0-p075 Tue Sep 26 09:27:40 PDT 2023"
        
        Returns:
            Dict with keys: design, date, vendor, program, version, spef_standard
        """
        version_info = {
            'design': '',
            'date': '',
            'vendor': '',
            'program': '',
            'version': '',
            'spef_standard': ''
        }
        
        if not spef_path.exists():
            return version_info
        
        lines = self._read_file_content(spef_path, max_lines=100)
        
        for line in lines:
            if line.startswith('*SPEF'):
                match = re.search(r'\*SPEF\s+"([^"]+)"', line)
                if match:
                    version_info['spef_standard'] = match.group(1)
            elif line.startswith('*DESIGN'):
                match = re.search(r'\*DESIGN\s+"([^"]+)"', line)
                if match:
                    version_info['design'] = match.group(1)
            elif line.startswith('*DATE'):
                match = re.search(r'\*DATE\s+"([^"]+)"', line)
                if match:
                    version_info['date'] = match.group(1)
            elif line.startswith('*VENDOR'):
                match = re.search(r'\*VENDOR\s+"([^"]+)"', line)
                if match:
                    version_info['vendor'] = match.group(1)
            elif line.startswith('*PROGRAM'):
                match = re.search(r'\*PROGRAM\s+"([^"]+)"', line)
                if match:
                    version_info['program'] = match.group(1)
            elif line.startswith('*VERSION'):
                match = re.search(r'\*VERSION\s+"([^"]+)"', line)
                if match:
                    version_info['version'] = match.group(1)
        
        return version_info
```

**_read_file_content**:
```python
def _read_file_content(self, file_path: Path, max_lines: int = 100) -> List[str]:
        """
        Read file content, supporting both plain text and gzip compressed files.
        
        Args:
            file_path: Path to the file
            max_lines: Maximum number of lines to read from start
            
        Returns:
            List of lines from the file
        """
        if not file_path.exists():
            return []
        
        try:
            # Check if file is gzipped
            if file_path.suffix == '.gz':
                try:
                    with gzip.open(file_path, 'rt', encoding='utf-8', errors='ignore') as f:
                        lines = []
                        for i, line in enumerate(f):
                            if i >= max_lines:
                                break
                            lines.append(line)
                        return lines
                except (gzip.BadGzipFile, OSError):
                    pass
            
            # Read as plain text file
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = []
                for i, line in enumerate(f):
                    if i >= max_lines:
                        break
                    lines.append(line)
                return lines
        except Exception as e:
            print(f"Warning: Failed to read {file_path}: {e}")
            return []
```

**_resolve_relative_path**:
```python
def _resolve_relative_path(self, relative_path: str, sta_log_dir: Path) -> Optional[Path]:
        """
        Resolve relative path from STA log to absolute path.
        
        Args:
            relative_path: Relative path from STA log
            sta_log_dir: Directory containing the STA log file
            
        Returns:
            Absolute path if exists, None otherwise
        """
        if not relative_path:
            return None
        
        try:
            clean_path = relative_path.strip().strip('"').strip("'")
            
            # Try absolute path first
            abs_path = Path(clean_path)
            if abs_path.is_absolute() and abs_path.exists():
                return abs_path
            
            # Resolve relative to STA log directory
            abs_path = (sta_log_dir / clean_path).resolve()
            if abs_path.exists():
                return abs_path
            
            # Try from project root
            if self.root:
                abs_path = (self.root / clean_path).resolve()
                if abs_path.exists():
                    return abs_path
        except Exception as e:
            print(f"Warning: Failed to resolve path {relative_path}: {e}")
        
        return None
```

**_match_pattern**:
```python
def _match_pattern(self, text: str, patterns: List[str]) -> Optional[str]:
        """
        Check if text matches any pattern.
        
        Args:
            text: Text to check
            patterns: List of patterns (supports wildcards)
            
        Returns:
            Matched pattern if found, None otherwise
        """
        for pattern in patterns:
            try:
                # Convert wildcard to regex
                regex_pattern = pattern
                if '*' in pattern and not pattern.startswith('^'):
                    regex_pattern = pattern.replace('*', '.*')
                
                if re.search(regex_pattern, text, re.IGNORECASE):
                    return pattern
            except re.error:
                # Regex error, try exact match
                if pattern.lower() in text.lower():
                    return pattern
        return None


# ============================================================================
# Entry Point (Template - Fixed, Golden-Aligned)
# ============================================================================

def init_checker() -> NetlistSpefVersionChecker:
    """Initialize and return the checker instance."""
    checker = NetlistSpefVersionChecker()
    checker.init_checker()
    return checker


if __name__ == '__main__':
    checker = init_checker()
    checker.execute_check()
    checker.write_output()
```

## âš ï¸ CRITICAL: Golden Helper Methods å¿…é¡»å®Œæ•´å¤ç”¨

**ç»å¯¹ç¦æ­¢ç®€åŒ–æˆ–é‡å†™ä¸Šé¢çš„Helperæ–¹æ³•ï¼**

### å¿…é¡»å®Œæ•´å¤åˆ¶çš„æ–¹æ³•:
1. `_extract_data()` - **å®Œæ•´å¤åˆ¶**ï¼Œä»parsed_dataæå–netlist_info, spef_info, errors
2. `_parse_sta_log()` - **å®Œæ•´å¤åˆ¶**ï¼Œä¸è¦ç®€åŒ–ä¸º`_parse_log_file()`
3. `_parse_netlist_version()` - **å®Œæ•´å¤åˆ¶**ï¼Œä»å®é™…æ–‡ä»¶å¤´è¯»å–ç‰ˆæœ¬
4. `_parse_spef_version()` - **å®Œæ•´å¤åˆ¶**ï¼Œä»SPEFæ–‡ä»¶è¯»å–IEEEç‰ˆæœ¬
5. `_read_file_content()` - **å®Œæ•´å¤åˆ¶**ï¼Œæ”¯æŒgzipå‹ç¼©æ–‡ä»¶
6. `_resolve_relative_path()` - **å®Œæ•´å¤åˆ¶**ï¼Œå¤„ç†ç›¸å¯¹è·¯å¾„
7. `_match_pattern()` - **å®Œæ•´å¤åˆ¶**ï¼Œé€šç”¨patternåŒ¹é…

### æ•°æ®ç»“æ„è¦æ±‚ (ä¸Goldenå®Œå…¨ä¸€è‡´):
- `found_items`: **Dict[str, Dict]** - keyä¸ºitemåï¼Œvalueä¸ºmetadata
- `missing_items`: **Dict[str, Dict]** - å¿…é¡»æ˜¯Dictï¼Œä¸è¦ç”¨List!
- `extra_items`: **Dict[str, Dict]** - keyä¸ºitemåï¼Œvalueä¸ºmetadata
- itemå‘½å: ä½¿ç”¨ `"Netlist File"`, `"SPEF File"` ç­‰å›ºå®šåç§°

### æ­£ç¡®ç¤ºä¾‹:
```python
# âœ… æ­£ç¡®: missing_itemsæ˜¯Dict
missing_items[f"Netlist File"] = {'reason': f"Status: {netlist_status}"}

# âŒ é”™è¯¯: missing_itemsæ˜¯List
missing_items.append(f"Netlist (Status: {netlist_status})")
```

**åŸå› **: è¿™äº›æ–¹æ³•å’Œæ•°æ®ç»“æ„ç»è¿‡æµ‹è¯•éªŒè¯ï¼Œå¿…é¡»å®Œå…¨ä¸€è‡´æ‰èƒ½é€šè¿‡å›å½’æµ‹è¯•ã€‚

**æ­£ç¡®åšæ³•**: å°†ä¸Šé¢çš„Helperæ–¹æ³•å’Œæ•°æ®ç»“æ„æ¨¡å¼åŸå°ä¸åŠ¨æ”¾å…¥`<helper_methods>`éƒ¨åˆ†

## ğŸ“‹ çœŸå® Log æ ·æœ¬ (æ­£åˆ™è¡¨è¾¾å¼è®¾è®¡ä¾æ®)

è¯·åŸºäºä»¥ä¸‹çœŸå®æ—¥å¿—è®¾è®¡æ­£åˆ™è¡¨è¾¾å¼ï¼š

### main
```
INFO: Starting STA analysis
INFO: Read Netlist: /designs/block_a/netlist_v1.v.gz
  > Status: Success
  > Version: Cadence Genus 23.15
INFO: Read SPEF: /designs/block_a/parasitic.spef.gz
  > Status: Success
  > SPEF Version: IEEE 1481-1999
INFO: Analysis complete
```


# ğŸ“‹ ä»»åŠ¡

ç”Ÿæˆ Checker çš„æ ¸å¿ƒæ–¹æ³•:

| å±æ€§ | å€¼ |
|------|-----|
| Item ID | `IMP-10-0-0-00` |
| Class Name | `Check_10_0_0_00` |
| Module | `IMP` |
| Description | Confirm the netlist/spef version is correct. |

### æ£€æŸ¥ä¸Šä¸‹æ–‡
- **Item**: `IMP-10-0-0-00` (Check_10_0_0_00)
- **æè¿°**: Confirm the netlist/spef version is correct.
- **æ–‡ä»¶ç±»å‹**: log
- **å‚è€ƒæ­£åˆ™**: `Read Netlist:\s*(.+)` | `Read SPEF:\s*(.+)` | `Status:\s*(Success|Failed)`
- **æå–å­—æ®µ**: (None)

<type_specifications hint="è¿è¡Œæ—¶æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©">
  <type id="1" needs_waiver="false">
    <pass_condition>Both files read with Status: Success</pass_condition>
    <fail_condition>Any file read failed</fail_condition>
  </type>
  <type id="2" needs_waiver="false">
    <pass_condition>Pattern items found in output</pass_condition>
    <fail_condition>Pattern items not found</fail_condition>
  </type>
  <type id="3" needs_waiver="true">
    <pass_condition>Pattern items found or waiver valid</pass_condition>
    <fail_condition>Pattern items not found and waiver invalid</fail_condition>
  </type>
  <type id="4" needs_waiver="true">
    <pass_condition>Check passed or waiver valid</pass_condition>
    <fail_condition>Check failed and waiver invalid/expired</fail_condition>
  </type>
</type_specifications>

<runtime_parameters hint="é‡è¦ï¼šå‚æ•°ä» self.item_data è·å–ï¼Œä¸æ˜¯ self.requirements">
  <pattern_items_usage types="Type2,Type3">
    <code_template><![CDATA[
# pattern_items ä» self.item_data è·å– (NOT self.requirements!)
requirements = self.item_data.get('requirements', {})
pattern_items = requirements.get('pattern_items', [])

# éå†åŒ¹é…ç¤ºä¾‹:
for item in pattern_items:
    if isinstance(item, str):
        pattern = item
    else:
        pattern = item.get('pattern', '')
    if pattern in extracted_value:
        matched = True
    ]]></code_template>
  </pattern_items_usage>
  <waive_items_usage types="Type3,Type4">
    <code_template><![CDATA[
# ä½¿ç”¨ WaiverHandlerMixin æä¾›çš„æ–¹æ³•
waivers = self.get_waivers()
waive_items_raw = waivers.get('waive_items', [])
waive_dict = self.parse_waive_items(waive_items_raw)

# åŒ¹é…åˆ¤æ–­ (åœ¨å¾ªç¯ä¸­ä½¿ç”¨):
for violation in violations:
    if self.match_waiver_entry(violation, waive_dict):
        waived_items.append(violation)
    else:
        unwaived_items.append(violation)
    ]]></code_template>
  </waive_items_usage>
</runtime_parameters>

# âš ï¸ CRITICAL: v2.0 ä¸‰å±‚æ¶æ„ - ä»£ç å¤ç”¨æ¨¡å¼

> **æ ¸å¿ƒåŸåˆ™: Type3/4 å¤ç”¨ Type2/1 çš„é€»è¾‘ï¼Œä¸è¦é‡å¤å®ç°ï¼**

## æ¶æ„è®¾è®¡

```
Layer 1: _parse_input_files()          # 4ä¸ªTypeå…±äº«ï¼Œè§£æä¸€æ¬¡
         â†“
Layer 2: å…±äº«é€»è¾‘æ¨¡å—                   # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
         - _boolean_check_logic()       # Type1/4 å…±äº« (å­˜åœ¨æ€§åˆ¤æ–­)
         - _pattern_check_logic()       # Type2/3 å…±äº« (æ­£åˆ™åŒ¹é…)
         â†“
Layer 3: _execute_typeN()              # ä½¿ç”¨æ¡†æ¶æ–¹æ³•
         - Type1: execute_boolean_check(parse_data_func, has_waiver=False)
         - Type2: execute_value_check(parse_data_func, has_waiver=False)
         - Type3: execute_value_check(parse_data_func, has_waiver=True)
         - Type4: execute_boolean_check(parse_data_func, has_waiver=True)
```

## æ¡†æ¶æ–¹æ³• API (CRITICAL)

### execute_boolean_check() - Type 1/4 ä½¿ç”¨

```python
self.execute_boolean_check(
    parse_data_func: Callable[[], tuple],  # è¿”å› (found_items, missing_items, extra_items)
    has_waiver: bool = False,               # Type1=False, Type4=True
    found_desc: str = "Item found",
    missing_desc: str = "Item missing",
    extra_desc: str = "Extra item",
    name_extractor: Callable = None         # å¯é€‰ï¼Œæ ¼å¼åŒ–nameçš„å‡½æ•°
) -> CheckResult
```

### execute_value_check() - Type 2/3 ä½¿ç”¨

```python
self.execute_value_check(
    parse_data_func: Callable[[], tuple],  # è¿”å› (found_items, missing_items, extra_items)
    has_waiver: bool = False,               # Type2=False, Type3=True
    info_items: Dict = None,                # å¯é€‰ï¼Œçº¯å±•ç¤ºçš„INFOé¡¹
    found_desc: str = "Pattern matched",
    missing_desc: str = "Pattern missing",
    extra_desc: str = "Extra item",
    extra_severity: Severity = Severity.WARN,  # extra_itemsçš„ä¸¥é‡ç¨‹åº¦
    name_extractor: Callable = None         # å¯é€‰ï¼Œæ ¼å¼åŒ–nameçš„å‡½æ•°
) -> CheckResult
```

## ä»£ç æ¨¡æ¿

### Layer 2: å…±äº«é€»è¾‘æ¨¡å— (åœ¨ <helper_methods> ä¸­å®ç°)

```python
def _boolean_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Boolean Check Logic (Type1/4 å…±äº«)
    
    æ ¸å¿ƒä¸šåŠ¡é€»è¾‘: æ£€æŸ¥é¡¹ç›®æ˜¯å¦å­˜åœ¨ (å­˜åœ¨æ€§åˆ¤æ–­)
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
    """
    # ä» parsed_data æå–æ•°æ®
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # ä¸šåŠ¡é€»è¾‘: åˆ¤æ–­æ˜¯å¦å­˜åœ¨
    # ... (å…·ä½“å®ç°)
    
    return found_items, missing_items, extra_items


def _pattern_check_logic(self, parsed_data: Dict[str, Any]) -> tuple:
    """
    Pattern Check Logic (Type2/3 å…±äº«)
    
    æ ¸å¿ƒä¸šåŠ¡é€»è¾‘: åŒ¹é… pattern_items (æ­£åˆ™åŒ¹é…)
    
    Returns:
        tuple: (found_items, missing_items, extra_items)
    """
    # è·å– pattern_items
    requirements = self.item_data.get('requirements', {})
    pattern_items = requirements.get('pattern_items', [])
    
    # ä» parsed_data åŒ¹é…
    found_items = {}
    missing_items = {}
    extra_items = {}
    
    # ä¸šåŠ¡é€»è¾‘: æ­£åˆ™åŒ¹é…
    # ... (å…·ä½“å®ç°)
    
    return found_items, missing_items, extra_items
```

### Layer 3: _execute_typeN() ä½¿ç”¨æ¡†æ¶æ–¹æ³•

```python
def _execute_type1(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 1: Boolean check - å­˜åœ¨å³ PASS"""
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Boolean Check Logic"""
        return self._boolean_check_logic(parsed_data)
    
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=False,
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


def _execute_type2(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 2: Value check - åŒ¹é… pattern_items"""
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Pattern Check Logic"""
        return self._pattern_check_logic(parsed_data)
    
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=False,
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )


def _execute_type3(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 3: Value check with waiver - å¤ç”¨ Type2 é€»è¾‘"""
    # âš ï¸ å¤ç”¨ Type2 çš„é€»è¾‘æ¨¡å— (ä¸è¦é‡å¤å®ç°ï¼)
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Pattern Check Logic (ä¸Type2ç›¸åŒ)"""
        return self._pattern_check_logic(parsed_data)
    
    return self.execute_value_check(
        parse_data_func=parse_data,
        has_waiver=True,  # Type3ç‰¹æœ‰: å¯ç”¨waiverå¤„ç†
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        extra_severity=Severity.FAIL,
        name_extractor=self._build_name_extractor()
    )


def _execute_type4(self, parsed_data: Dict[str, Any]) -> CheckResult:
    """Type 4: Boolean check with waiver - å¤ç”¨ Type1 é€»è¾‘"""
    # âš ï¸ å¤ç”¨ Type1 çš„é€»è¾‘æ¨¡å— (ä¸è¦é‡å¤å®ç°ï¼)
    def parse_data():
        """è°ƒç”¨å…±äº«çš„Boolean Check Logic (ä¸Type1ç›¸åŒ)"""
        return self._boolean_check_logic(parsed_data)
    
    return self.execute_boolean_check(
        parse_data_func=parse_data,
        has_waiver=True,  # Type4ç‰¹æœ‰: å¯ç”¨waiverå¤„ç†
        found_desc=self.FOUND_DESC,
        missing_desc=self.MISSING_DESC,
        extra_desc=self.EXTRA_DESC,
        name_extractor=self._build_name_extractor()
    )
```

### name_extractor è¾…åŠ©æ–¹æ³• (å¯é€‰)

```python
def _build_name_extractor(self):
    """è¿”å› name_extractor å‡½æ•°ï¼Œç”¨äºæ ¼å¼åŒ–è¾“å‡ºåç§°"""
    def extract_name(name: str, metadata: Any) -> str:
        # æ ¹æ® metadata æ ¼å¼åŒ– name
        if isinstance(metadata, dict):
            if metadata.get('version'):
                return f"{name} (v{metadata['version']})"
            if metadata.get('path'):
                return f"{name}: {Path(metadata['path']).name}"
        return name
    return extract_name
```

## å®æ–½è¦æ±‚

1. **å¿…é¡»æå–å…±äº«æ¨¡å—**: å°† Boolean/Pattern åˆ¤æ–­é€»è¾‘æå–åˆ° `_boolean_check_logic()` å’Œ `_pattern_check_logic()`
2. **Type3/4 ç¦æ­¢é‡å¤å®ç°**: ç›´æ¥è°ƒç”¨å¯¹åº”çš„å…±äº«æ¨¡å—ï¼Œåªæ”¹å˜ `has_waiver` å‚æ•°
3. **ä½¿ç”¨æ¡†æ¶æ–¹æ³•**: `execute_boolean_check()` (Type1/4) å’Œ `execute_value_check()` (Type2/3)
4. **æ‰€æœ‰å…±äº«æ¨¡å—æ”¾åœ¨ <helper_methods>**: ç¡®ä¿å¯ä»¥è¢«æ‰€æœ‰ Type è°ƒç”¨

## ä¼˜åŠ¿

- **ä»£ç è¡Œæ•°å‡å°‘**: 357 lines (Golden 1242 â†’ v2.0 885)
- **é€»è¾‘ç»Ÿä¸€**: Type1/4 å…±äº« Boolean é€»è¾‘ï¼ŒType2/3 å…±äº« Pattern é€»è¾‘
- **æ¡†æ¶è‡ªåŠ¨å¤„ç†**: waiverå¤„ç†ã€found/missingåˆ†ç±»ã€outputæ„å»º
- **æ˜“äºç»´æŠ¤**: ä¿®æ”¹ä¸€æ¬¡ï¼Œ4ä¸ª Type åŒæ­¥æ›´æ–°


# ğŸ“¤ è¾“å‡ºè¦æ±‚

> **è¯¦ç»† API å¥‘çº¦è§ System Prompt Section 2**

## âš ï¸ CRITICAL æé†’

1. **æ–¹æ³•ç­¾å**: `_execute_typeN(self, parsed_data)` - å¿…é¡»æ¥æ”¶ parsed_data
2. **Helper Methods**: 
   - `self._xxx()` å¿…é¡»åœ¨ `<helper_methods>` ä¸­å®šä¹‰
   - **å¿…é¡»å®Œæ•´å¤ç”¨Goldenæä¾›çš„Helperæ–¹æ³•ï¼Œç¦æ­¢ç®€åŒ–ï¼**
   - åŒ…æ‹¬: `_parse_sta_log`, `_parse_netlist_version`, `_parse_spef_version`, `_read_file_content`, `_resolve_relative_path`, `_match_pattern`
3. **Metadata**: è§£ææ—¶ `self._metadata['key'] = {'line_number': N, 'file_path': str}`, ä½¿ç”¨æ—¶ `meta.get('line_number', 0)`
4. **Waiver (Type3/4)**: ä½¿ç”¨ `self.is_item_waived_word_level()` æˆ– word-level åŒ¹é…

## è¾“å‡º XML æ ¼å¼

```xml
<thoughts>
1. æ£€æŸ¥ç›®æ ‡ 2. æ•°æ®æµ 3. è¾…åŠ©æ–¹æ³•(å¤ç”¨Golden) 4. Pass/Failé€»è¾‘ 5. Metadataè¿½è¸ª
</thoughts>

<class_constants>
FOUND_DESC = "..." / MISSING_DESC = "..." / ...
</class_constants>

<parse_method>
def _parse_input_files(self) -> Dict[str, Any]: ...
</parse_method>

<execute_type1>...<execute_type2>...<execute_type3>...<execute_type4>

<helper_methods>
# âš ï¸ æ‰€æœ‰ self._xxx() è°ƒç”¨å¿…é¡»åœ¨è¿™é‡Œå®šä¹‰!
# âš ï¸ å¿…é¡»å®Œæ•´å¤ç”¨Goldençš„Helperæ–¹æ³•ï¼Œä¸è¦ç®€åŒ–!
</helper_methods>
```